{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EMNIST.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G2vPlgvFvLFe",
        "outputId": "dc993603-7ecd-4600-f960-662512d343db"
      },
      "source": [
        "!pip install emnist"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting emnist\n",
            "  Downloading https://files.pythonhosted.org/packages/d1/f4/78b24acbef9e8fe976dda700f16a3606f3b8363b015bc555f8050fbbd8ac/emnist-0.0-py3-none-any.whl\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from emnist) (4.41.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from emnist) (1.19.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from emnist) (2.23.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->emnist) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->emnist) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->emnist) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->emnist) (1.24.3)\n",
            "Installing collected packages: emnist\n",
            "Successfully installed emnist-0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cJhHvhXOvP8b"
      },
      "source": [
        "from emnist import extract_training_samples\n",
        "#  ['balanced', 'byclass', 'bymerge', 'digits', 'letters', 'mnist']\n",
        "from emnist import extract_test_samples\n",
        "import pandas as pd \n",
        "import numpy as np\n",
        "import datetime \n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.model_selection import GridSearchCV"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5kY0y9wf8bHM"
      },
      "source": [
        "## **Reshape**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kXc3uV05vUsm",
        "outputId": "09efe93f-3b63-4dea-8899-6c16c920bcab"
      },
      "source": [
        "images_train, trainY = extract_training_samples('balanced')\n",
        "images_test, testY = extract_test_samples('balanced')\n",
        "trainX =images_train.reshape(images_train.shape[0],28*28)\n",
        "testX = images_test.reshape(images_test.shape[0],28*28)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading emnist.zip: 536MB [00:07, 71.2MB/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aHSgsUQnLPQU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c7ee015-f211-4097-e82b-edcd1fac5891"
      },
      "source": [
        "images_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(112800, 28, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xs7iHiALLPQV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "094d2e92-b4b9-4761-ac16-5a96871de775"
      },
      "source": [
        "trainX.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(112800, 784)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zUc7gdrz8liT"
      },
      "source": [
        "## **Split training & validation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7k0ecYLv7xrS"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "trainX, validationX, trainY, validationY = train_test_split(trainX,trainY,test_size = 0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ZUbHxs-82HX"
      },
      "source": [
        "##**Normalization**##"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Llh38BNi8609"
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "scaler.fit(trainX)\n",
        "train = scaler.transform(trainX)\n",
        "validation = scaler.transform(validationX)\n",
        "test = scaler.transform(testX)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v0VH1b5HJs7C"
      },
      "source": [
        "##**Imply to different models**##"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9yLy9NSHIyF7"
      },
      "source": [
        "#SVM \n",
        "from sklearn import svm\n",
        "start = datetime.datetime.now()\n",
        "clf = svm.SVC()\n",
        "clf.fit(trainX,trainY)\n",
        "#time used for training the model\n",
        "time_used = datetime.datetime.now() - start\n",
        "print(\"time_usage_for_training:\", time_used)\n",
        "pred_train = clf.predict(trainX)\n",
        "pred_val = clf.predict(validationX)\n",
        "pred_test = clf.predict(testX)\n",
        "#accuracy, precision, F1 score, recall \n",
        "precision_train = precision_score(trainY, pred_train, average = \"micro\")\n",
        "recall_train = recall_score(trainY, pred_train, average = \"micro\")\n",
        "accuracy_train = accuracy_score(trainY, pred_train)\n",
        "f1score_train = f1_score(trainY, pred_train, average = \"micro\")\n",
        "precision_val = precision_score(validationY, pred_val, average = \"micro\")\n",
        "recall_val = recall_score(validationY, pred_val, average = \"micro\")\n",
        "accuracy_val = accuracy_score(validationY, pred_val)\n",
        "f1score_val = f1_score(validationY, pred_val, average = \"micro\")\n",
        "precision_test = precision_score(testY, pred_test, average = \"micro\")\n",
        "recall_test = recall_score(testY, pred_test, average = \"micro\")\n",
        "accuracy_test = accuracy_score(testY, pred_test)\n",
        "f1score_test = f1_score(testY, pred_test, average = \"micro\")\n",
        "print(\"preison_train:\", precision_train)\n",
        "print(\"recall_train:\", recall_train)\n",
        "print(\"accuracy_train:\", accuracy_train)\n",
        "print(\"f1_score_train:\", f1score_train)\n",
        "print(\"preison_validation:\", precision_val)\n",
        "print(\"recall_validation:\", recall_val)\n",
        "print(\"accuracy_validation:\", accuracy_val)\n",
        "print(\"f1_score_validation:\", f1score_val)\n",
        "print(\"preison_test:\", precision_test)\n",
        "print(\"recall_test:\", recall_test)\n",
        "print(\"accuracy_test:\", accuracy_test)\n",
        "print(\"f1_score_test:\", f1score_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8iEpzJAGKint"
      },
      "source": [
        "#knn\n",
        "from sklearn.neighbors import KNeighborsClassifier \n",
        "start = datetime.datetime.now()\n",
        "neigh = KNeighborsClassifier(n_neighbors=5)\n",
        "neigh.fit(trainX,trainY)\n",
        "#time used for training the model\n",
        "time_used = datetime.datetime.now() - start\n",
        "print(\"time_usage_for_training:\", time_used)\n",
        "pred_train = neigh.predict(trainX)\n",
        "pred_train = neigh.predict(trainX)\n",
        "pred_val = neigh.predict(validationX)\n",
        "pred_test = neigh.predict(testX)\n",
        "#accuracy, precision, F1 score, recall \n",
        "precision_train = precision_score(trainY, pred_train, average = \"micro\")\n",
        "recall_train = recall_score(trainY, pred_train, average = \"micro\")\n",
        "accuracy_train = accuracy_score(trainY, pred_train)\n",
        "f1score_train = f1_score(trainY, pred_train, average = \"micro\")\n",
        "precision_val = precision_score(validationY, pred_val, average = \"micro\")\n",
        "recall_val = recall_score(validationY, pred_val, average = \"micro\")\n",
        "accuracy_val = accuracy_score(validationY, pred_val)\n",
        "f1score_val = f1_score(validationY, pred_val, average = \"micro\")\n",
        "precision_test = precision_score(testY, pred_test, average = \"micro\")\n",
        "recall_test = recall_score(testY, pred_test, average = \"micro\")\n",
        "accuracy_test = accuracy_score(testY, pred_test)\n",
        "f1score_test = f1_score(testY, pred_test, average = \"micro\")\n",
        "print(\"preison_train:\", precision_train)\n",
        "print(\"recall_train:\", recall_train)\n",
        "print(\"accuracy_train:\", accuracy_train)\n",
        "print(\"f1_score_train:\", f1score_train)\n",
        "print(\"preison_validation:\", precision_val)\n",
        "print(\"recall_validation:\", recall_val)\n",
        "print(\"accuracy_validation:\", accuracy_val)\n",
        "print(\"f1_score_validation:\", f1score_val)\n",
        "print(\"preison_test:\", precision_test)\n",
        "print(\"recall_test:\", recall_test)\n",
        "print(\"accuracy_test:\", accuracy_test)\n",
        "print(\"f1_score_test:\", f1score_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YdSC_7PaMSDH"
      },
      "source": [
        "#Logistic regression\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "start = datetime.datetime.now()\n",
        "clf = LogisticRegression(max_iter = 30000)\n",
        "clf.fit(trainX,trainY)\n",
        "#time used for training the model\n",
        "time_used = datetime.datetime.now() - start\n",
        "print(\"time_usage_for_training:\", time_used)\n",
        "pred_train = clf.predict(trainX)\n",
        "pred_train = clf.predict(trainX)\n",
        "pred_val = clf.predict(validationX)\n",
        "pred_test = clf.predict(testX)\n",
        "#accuracy, precision, F1 score, recall \n",
        "precision_train = precision_score(trainY, pred_train, average = \"micro\")\n",
        "recall_train = recall_score(trainY, pred_train, average = \"micro\")\n",
        "accuracy_train = accuracy_score(trainY, pred_train)\n",
        "f1score_train = f1_score(trainY, pred_train, average = \"micro\")\n",
        "precision_val = precision_score(validationY, pred_val, average = \"micro\")\n",
        "recall_val = recall_score(validationY, pred_val, average = \"micro\")\n",
        "accuracy_val = accuracy_score(validationY, pred_val)\n",
        "f1score_val = f1_score(validationY, pred_val, average = \"micro\")\n",
        "precision_test = precision_score(testY, pred_test, average = \"micro\")\n",
        "recall_test = recall_score(testY, pred_test, average = \"micro\")\n",
        "accuracy_test = accuracy_score(testY, pred_test)\n",
        "f1score_test = f1_score(testY, pred_test, average = \"micro\")\n",
        "print(\"preison_train:\", precision_train)\n",
        "print(\"recall_train:\", recall_train)\n",
        "print(\"accuracy_train:\", accuracy_train)\n",
        "print(\"f1_score_train:\", f1score_train)\n",
        "print(\"preison_validation:\", precision_val)\n",
        "print(\"recall_validation:\", recall_val)\n",
        "print(\"accuracy_validation:\", accuracy_val)\n",
        "print(\"f1_score_validation:\", f1score_val)\n",
        "print(\"preison_test:\", precision_test)\n",
        "print(\"recall_test:\", recall_test)\n",
        "print(\"accuracy_test:\", accuracy_test)\n",
        "print(\"f1_score_test:\", f1score_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0bZiydKQMSN0"
      },
      "source": [
        "#Decision tree classification \n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "start = datetime.datetime.now()\n",
        "clf = DecisionTreeClassifier(max_depth=10)\n",
        "clf.fit(trainX, trainY)\n",
        "#time used for training the model\n",
        "time_used = datetime.datetime.now() - start\n",
        "print(\"time_usage_for_training:\", time_used)\n",
        "pred_train = clf.predict(trainX)\n",
        "pred_train = clf.predict(trainX)\n",
        "pred_val = clf.predict(validationX)\n",
        "pred_test = clf.predict(testX)\n",
        "#accuracy, precision, F1 score, recall \n",
        "precision_train = precision_score(trainY, pred_train, average = \"micro\")\n",
        "recall_train = recall_score(trainY, pred_train, average = \"micro\")\n",
        "accuracy_train = accuracy_score(trainY, pred_train)\n",
        "f1score_train = f1_score(trainY, pred_train, average = \"micro\")\n",
        "precision_val = precision_score(validationY, pred_val, average = \"micro\")\n",
        "recall_val = recall_score(validationY, pred_val, average = \"micro\")\n",
        "accuracy_val = accuracy_score(validationY, pred_val)\n",
        "f1score_val = f1_score(validationY, pred_val, average = \"micro\")\n",
        "precision_test = precision_score(testY, pred_test, average = \"micro\")\n",
        "recall_test = recall_score(testY, pred_test, average = \"micro\")\n",
        "accuracy_test = accuracy_score(testY, pred_test)\n",
        "f1score_test = f1_score(testY, pred_test, average = \"micro\")\n",
        "print(\"preison_train:\", precision_train)\n",
        "print(\"recall_train:\", recall_train)\n",
        "print(\"accuracy_train:\", accuracy_train)\n",
        "print(\"f1_score_train:\", f1score_train)\n",
        "print(\"preison_validation:\", precision_val)\n",
        "print(\"recall_validation:\", recall_val)\n",
        "print(\"accuracy_validation:\", accuracy_val)\n",
        "print(\"f1_score_validation:\", f1score_val)\n",
        "print(\"preison_test:\", precision_test)\n",
        "print(\"recall_test:\", recall_test)\n",
        "print(\"accuracy_test:\", accuracy_test)\n",
        "print(\"f1_score_test:\", f1score_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ME19JBhHMSXv"
      },
      "source": [
        "#Random forest classification \n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "start = datetime.datetime.now()\n",
        "clf = RandomForestClassifier()\n",
        "clf.fit(trainX, trainY)\n",
        "#time used for training the model\n",
        "time_used = datetime.datetime.now() - start\n",
        "print(\"time_usage_for_training:\", time_used)\n",
        "pred_train = clf.predict(trainX)\n",
        "pred_train = clf.predict(trainX)\n",
        "pred_val = clf.predict(validationX)\n",
        "pred_test = clf.predict(testX)\n",
        "#accuracy, precision, F1 score, recall \n",
        "precision_train = precision_score(trainY, pred_train, average = \"micro\")\n",
        "recall_train = recall_score(trainY, pred_train, average = \"micro\")\n",
        "accuracy_train = accuracy_score(trainY, pred_train)\n",
        "f1score_train = f1_score(trainY, pred_train, average = \"micro\")\n",
        "precision_val = precision_score(validationY, pred_val, average = \"micro\")\n",
        "recall_val = recall_score(validationY, pred_val, average = \"micro\")\n",
        "accuracy_val = accuracy_score(validationY, pred_val)\n",
        "f1score_val = f1_score(validationY, pred_val, average = \"micro\")\n",
        "precision_test = precision_score(testY, pred_test, average = \"micro\")\n",
        "recall_test = recall_score(testY, pred_test, average = \"micro\")\n",
        "accuracy_test = accuracy_score(testY, pred_test)\n",
        "f1score_test = f1_score(testY, pred_test, average = \"micro\")\n",
        "print(\"preison_train:\", precision_train)\n",
        "print(\"recall_train:\", recall_train)\n",
        "print(\"accuracy_train:\", accuracy_train)\n",
        "print(\"f1_score_train:\", f1score_train)\n",
        "print(\"preison_validation:\", precision_val)\n",
        "print(\"recall_validation:\", recall_val)\n",
        "print(\"accuracy_validation:\", accuracy_val)\n",
        "print(\"f1_score_validation:\", f1score_val)\n",
        "print(\"preison_test:\", precision_test)\n",
        "print(\"recall_test:\", recall_test)\n",
        "print(\"accuracy_test:\", accuracy_test)\n",
        "print(\"f1_score_test:\", f1score_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "smJiBHM_LPQd"
      },
      "source": [
        "import tensorflow as tf \n",
        "from tensorflow import keras \n",
        "from tensorflow.keras import layers \n",
        "from tensorflow.keras import Sequential  \n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Conv2D, MaxPool2D\n",
        "from tensorflow.keras.utils import to_categorical \n",
        "import sklearn\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xxcYSrFBLPQe"
      },
      "source": [
        "images_train, trainY = extract_training_samples('balanced')\n",
        "images_test, testY = extract_test_samples('balanced')\n",
        "#reshape data\n",
        "trainX =images_train.reshape(images_train.shape[0],28,28,1)\n",
        "testX = images_test.reshape(images_test.shape[0],28,28,1)\n",
        "#normalization \n",
        "trainX = tf.keras.utils.normalize(trainX, axis=-1, order=2)\n",
        "testX = tf.keras.utils.normalize(testX, axis=-1, order=2)\n",
        "#train validation split \n",
        "trainX, validationX, trainY, validationY = train_test_split(trainX,trainY,test_size = 0.2)\n",
        "#to_caegorical \n",
        "#trainY = to_categorical (trainY)\n",
        "#validationY = to_categorical(validationY)\n",
        "#testY = to_categorical(testY)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "POpkQJQOLPQe"
      },
      "source": [
        "#Experiment 1-- Number of convolutional layers \n",
        "nets = 3 \n",
        "model = [0]*nets \n",
        "for j in range(3):\n",
        "    model[j] = Sequential()\n",
        "    model[j].add(Conv2D(24,kernel_size=5,padding='same',activation='relu',\n",
        "            input_shape=(28,28,1)))\n",
        "    model[j].add(MaxPool2D())\n",
        "    if j>0:\n",
        "        model[j].add(Conv2D(48,kernel_size=5,padding='same',activation='relu'))\n",
        "        model[j].add(MaxPool2D())\n",
        "    if j>1:\n",
        "        model[j].add(Conv2D(64,kernel_size=5,padding='same',activation='relu'))\n",
        "        model[j].add(MaxPool2D(padding='same'))\n",
        "    model[j].add(Flatten())\n",
        "    model[j].add(Dense(256, activation='relu'))\n",
        "    model[j].add(Dense(47, activation='sigmoid'))\n",
        "    model[j].compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r-9D4l0vLPQf",
        "outputId": "a7211cad-3e23-4eb1-b438-647ec0f72bba"
      },
      "source": [
        "train_result = []\n",
        "for i in range (3):\n",
        "    train = model[i].fit(trainX, trainY,batch_size = 128, epochs = 20,\n",
        "                 validation_data=(validationX,validationY))\n",
        "    train_result.append(train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "705/705 [==============================] - 49s 68ms/step - loss: 0.0780 - accuracy: 0.4776 - val_loss: 0.0297 - val_accuracy: 0.7645\n",
            "Epoch 2/20\n",
            "705/705 [==============================] - 47s 67ms/step - loss: 0.0270 - accuracy: 0.7843 - val_loss: 0.0250 - val_accuracy: 0.7929\n",
            "Epoch 3/20\n",
            "705/705 [==============================] - 47s 67ms/step - loss: 0.0221 - accuracy: 0.8231 - val_loss: 0.0222 - val_accuracy: 0.8217\n",
            "Epoch 4/20\n",
            "705/705 [==============================] - 47s 67ms/step - loss: 0.0198 - accuracy: 0.8384 - val_loss: 0.0212 - val_accuracy: 0.8281\n",
            "Epoch 5/20\n",
            "705/705 [==============================] - 47s 66ms/step - loss: 0.0182 - accuracy: 0.8506 - val_loss: 0.0203 - val_accuracy: 0.8339\n",
            "Epoch 6/20\n",
            "705/705 [==============================] - 48s 67ms/step - loss: 0.0167 - accuracy: 0.8619 - val_loss: 0.0199 - val_accuracy: 0.8359\n",
            "Epoch 7/20\n",
            "705/705 [==============================] - 48s 68ms/step - loss: 0.0158 - accuracy: 0.8690 - val_loss: 0.0198 - val_accuracy: 0.8397\n",
            "Epoch 8/20\n",
            "705/705 [==============================] - 47s 67ms/step - loss: 0.0148 - accuracy: 0.8787 - val_loss: 0.0196 - val_accuracy: 0.8403\n",
            "Epoch 9/20\n",
            "705/705 [==============================] - 47s 67ms/step - loss: 0.0138 - accuracy: 0.8855 - val_loss: 0.0198 - val_accuracy: 0.8391\n",
            "Epoch 10/20\n",
            "705/705 [==============================] - 47s 66ms/step - loss: 0.0129 - accuracy: 0.8945 - val_loss: 0.0199 - val_accuracy: 0.8422\n",
            "Epoch 11/20\n",
            "705/705 [==============================] - 47s 67ms/step - loss: 0.0119 - accuracy: 0.9028 - val_loss: 0.0201 - val_accuracy: 0.8391\n",
            "Epoch 12/20\n",
            "705/705 [==============================] - 47s 67ms/step - loss: 0.0111 - accuracy: 0.9113 - val_loss: 0.0205 - val_accuracy: 0.8431\n",
            "Epoch 13/20\n",
            "705/705 [==============================] - 47s 67ms/step - loss: 0.0101 - accuracy: 0.9195 - val_loss: 0.0214 - val_accuracy: 0.8391\n",
            "Epoch 14/20\n",
            "705/705 [==============================] - 47s 67ms/step - loss: 0.0094 - accuracy: 0.9252 - val_loss: 0.0220 - val_accuracy: 0.8398\n",
            "Epoch 15/20\n",
            "705/705 [==============================] - 48s 68ms/step - loss: 0.0084 - accuracy: 0.9366 - val_loss: 0.0233 - val_accuracy: 0.8339\n",
            "Epoch 16/20\n",
            "705/705 [==============================] - 48s 68ms/step - loss: 0.0077 - accuracy: 0.9410 - val_loss: 0.0239 - val_accuracy: 0.8315\n",
            "Epoch 17/20\n",
            "705/705 [==============================] - 48s 68ms/step - loss: 0.0069 - accuracy: 0.9479 - val_loss: 0.0251 - val_accuracy: 0.8336\n",
            "Epoch 18/20\n",
            "705/705 [==============================] - 48s 68ms/step - loss: 0.0062 - accuracy: 0.9528 - val_loss: 0.0267 - val_accuracy: 0.8330\n",
            "Epoch 19/20\n",
            "705/705 [==============================] - 48s 68ms/step - loss: 0.0057 - accuracy: 0.9578 - val_loss: 0.0272 - val_accuracy: 0.8328\n",
            "Epoch 20/20\n",
            "705/705 [==============================] - 48s 68ms/step - loss: 0.0050 - accuracy: 0.9652 - val_loss: 0.0286 - val_accuracy: 0.8304\n",
            "Epoch 1/20\n",
            "705/705 [==============================] - 106s 150ms/step - loss: 0.0919 - accuracy: 0.4048 - val_loss: 0.0254 - val_accuracy: 0.7987\n",
            "Epoch 2/20\n",
            "705/705 [==============================] - 104s 148ms/step - loss: 0.0233 - accuracy: 0.8119 - val_loss: 0.0208 - val_accuracy: 0.8295\n",
            "Epoch 3/20\n",
            "705/705 [==============================] - 105s 150ms/step - loss: 0.0189 - accuracy: 0.8434 - val_loss: 0.0193 - val_accuracy: 0.8404\n",
            "Epoch 4/20\n",
            "705/705 [==============================] - 104s 148ms/step - loss: 0.0167 - accuracy: 0.8595 - val_loss: 0.0175 - val_accuracy: 0.8514\n",
            "Epoch 5/20\n",
            "705/705 [==============================] - 105s 148ms/step - loss: 0.0152 - accuracy: 0.8711 - val_loss: 0.0172 - val_accuracy: 0.8536\n",
            "Epoch 6/20\n",
            "705/705 [==============================] - 101s 143ms/step - loss: 0.0140 - accuracy: 0.8812 - val_loss: 0.0166 - val_accuracy: 0.8618\n",
            "Epoch 7/20\n",
            "705/705 [==============================] - 101s 144ms/step - loss: 0.0130 - accuracy: 0.8887 - val_loss: 0.0172 - val_accuracy: 0.8583\n",
            "Epoch 8/20\n",
            "705/705 [==============================] - 100s 142ms/step - loss: 0.0120 - accuracy: 0.8978 - val_loss: 0.0165 - val_accuracy: 0.8641\n",
            "Epoch 9/20\n",
            "705/705 [==============================] - 101s 143ms/step - loss: 0.0111 - accuracy: 0.9052 - val_loss: 0.0172 - val_accuracy: 0.8597\n",
            "Epoch 10/20\n",
            "705/705 [==============================] - 100s 143ms/step - loss: 0.0104 - accuracy: 0.9118 - val_loss: 0.0171 - val_accuracy: 0.8633\n",
            "Epoch 11/20\n",
            "705/705 [==============================] - 101s 143ms/step - loss: 0.0096 - accuracy: 0.9185 - val_loss: 0.0173 - val_accuracy: 0.8628\n",
            "Epoch 12/20\n",
            "705/705 [==============================] - 101s 143ms/step - loss: 0.0089 - accuracy: 0.9239 - val_loss: 0.0184 - val_accuracy: 0.8594\n",
            "Epoch 13/20\n",
            "705/705 [==============================] - 101s 143ms/step - loss: 0.0082 - accuracy: 0.9306 - val_loss: 0.0193 - val_accuracy: 0.8540\n",
            "Epoch 14/20\n",
            "705/705 [==============================] - 101s 144ms/step - loss: 0.0076 - accuracy: 0.9344 - val_loss: 0.0204 - val_accuracy: 0.8518\n",
            "Epoch 15/20\n",
            "705/705 [==============================] - 101s 143ms/step - loss: 0.0070 - accuracy: 0.9412 - val_loss: 0.0205 - val_accuracy: 0.8570\n",
            "Epoch 16/20\n",
            "705/705 [==============================] - 101s 143ms/step - loss: 0.0066 - accuracy: 0.9445 - val_loss: 0.0221 - val_accuracy: 0.8562\n",
            "Epoch 17/20\n",
            "705/705 [==============================] - 103s 146ms/step - loss: 0.0061 - accuracy: 0.9483 - val_loss: 0.0234 - val_accuracy: 0.8544\n",
            "Epoch 18/20\n",
            "705/705 [==============================] - 100s 142ms/step - loss: 0.0056 - accuracy: 0.9536 - val_loss: 0.0242 - val_accuracy: 0.8532\n",
            "Epoch 19/20\n",
            "705/705 [==============================] - 100s 142ms/step - loss: 0.0052 - accuracy: 0.9572 - val_loss: 0.0253 - val_accuracy: 0.8509\n",
            "Epoch 20/20\n",
            "705/705 [==============================] - 100s 142ms/step - loss: 0.0048 - accuracy: 0.9620 - val_loss: 0.0271 - val_accuracy: 0.8503\n",
            "Epoch 1/20\n",
            "705/705 [==============================] - 131s 185ms/step - loss: 0.0921 - accuracy: 0.3657 - val_loss: 0.0229 - val_accuracy: 0.8158\n",
            "Epoch 2/20\n",
            "705/705 [==============================] - 130s 185ms/step - loss: 0.0206 - accuracy: 0.8267 - val_loss: 0.0182 - val_accuracy: 0.8445\n",
            "Epoch 3/20\n",
            "705/705 [==============================] - 130s 185ms/step - loss: 0.0166 - accuracy: 0.8564 - val_loss: 0.0171 - val_accuracy: 0.8516\n",
            "Epoch 4/20\n",
            "705/705 [==============================] - 130s 184ms/step - loss: 0.0146 - accuracy: 0.8735 - val_loss: 0.0161 - val_accuracy: 0.8581\n",
            "Epoch 5/20\n",
            "705/705 [==============================] - 130s 184ms/step - loss: 0.0134 - accuracy: 0.8819 - val_loss: 0.0157 - val_accuracy: 0.8650\n",
            "Epoch 6/20\n",
            "705/705 [==============================] - 130s 184ms/step - loss: 0.0123 - accuracy: 0.8915 - val_loss: 0.0156 - val_accuracy: 0.8669\n",
            "Epoch 7/20\n",
            "705/705 [==============================] - 130s 184ms/step - loss: 0.0114 - accuracy: 0.8997 - val_loss: 0.0154 - val_accuracy: 0.8677\n",
            "Epoch 8/20\n",
            "705/705 [==============================] - 130s 184ms/step - loss: 0.0106 - accuracy: 0.9058 - val_loss: 0.0153 - val_accuracy: 0.8688\n",
            "Epoch 9/20\n",
            "705/705 [==============================] - 130s 184ms/step - loss: 0.0098 - accuracy: 0.9134 - val_loss: 0.0154 - val_accuracy: 0.8691\n",
            "Epoch 10/20\n",
            "705/705 [==============================] - 130s 184ms/step - loss: 0.0091 - accuracy: 0.9175 - val_loss: 0.0157 - val_accuracy: 0.8723\n",
            "Epoch 11/20\n",
            "705/705 [==============================] - 143s 203ms/step - loss: 0.0085 - accuracy: 0.9249 - val_loss: 0.0168 - val_accuracy: 0.8685\n",
            "Epoch 12/20\n",
            "705/705 [==============================] - 155s 220ms/step - loss: 0.0078 - accuracy: 0.9298 - val_loss: 0.0172 - val_accuracy: 0.8710\n",
            "Epoch 13/20\n",
            "705/705 [==============================] - 156s 222ms/step - loss: 0.0070 - accuracy: 0.9359 - val_loss: 0.0187 - val_accuracy: 0.8625\n",
            "Epoch 14/20\n",
            "705/705 [==============================] - 169s 240ms/step - loss: 0.0064 - accuracy: 0.9433 - val_loss: 0.0190 - val_accuracy: 0.8664\n",
            "Epoch 15/20\n",
            "705/705 [==============================] - 160s 227ms/step - loss: 0.0059 - accuracy: 0.9488 - val_loss: 0.0203 - val_accuracy: 0.8615\n",
            "Epoch 16/20\n",
            "705/705 [==============================] - 157s 223ms/step - loss: 0.0055 - accuracy: 0.9517 - val_loss: 0.0216 - val_accuracy: 0.8629\n",
            "Epoch 17/20\n",
            "705/705 [==============================] - 134s 191ms/step - loss: 0.0050 - accuracy: 0.9564 - val_loss: 0.0238 - val_accuracy: 0.8598\n",
            "Epoch 18/20\n",
            "705/705 [==============================] - 137s 194ms/step - loss: 0.0048 - accuracy: 0.9579 - val_loss: 0.0241 - val_accuracy: 0.8594\n",
            "Epoch 19/20\n",
            "705/705 [==============================] - 141s 199ms/step - loss: 0.0044 - accuracy: 0.9629 - val_loss: 0.0254 - val_accuracy: 0.8590\n",
            "Epoch 20/20\n",
            "705/705 [==============================] - 143s 203ms/step - loss: 0.0041 - accuracy: 0.9646 - val_loss: 0.0263 - val_accuracy: 0.8588\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "szx2sku2LPQg",
        "outputId": "186907c9-3e65-4912-a14d-1aaef97f2138"
      },
      "source": [
        "print(np.mean(train_result[0].history['accuracy']))\n",
        "print(np.mean(train_result[1].history['accuracy']))\n",
        "print(np.mean(train_result[2].history['accuracy']))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8828280150890351\n",
            "0.8934857040643692\n",
            "0.9004792749881745\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tINZyWtGLPQh"
      },
      "source": [
        "#Experiment 2 \n",
        "nets = 6\n",
        "model = [0] *nets\n",
        "for j in range(6):\n",
        "    model[j] = Sequential()\n",
        "    model[j].add(Conv2D(j*8+8,kernel_size=5,activation='relu',input_shape=(28,28,1)))\n",
        "    model[j].add(MaxPool2D())\n",
        "    model[j].add(Conv2D(j*16+16,kernel_size=5,activation='relu'))\n",
        "    model[j].add(MaxPool2D())\n",
        "    model[j].add(Flatten())\n",
        "    model[j].add(Dense(256, activation='relu'))\n",
        "    model[j].add(Dense(47, activation='sigmoid'))\n",
        "    model[j].compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b-gMjM83LPQh",
        "outputId": "34676e10-d7d0-4909-b2b5-f691025ef74e"
      },
      "source": [
        "train_result = []\n",
        "for i in range (6):\n",
        "    train = model[i].fit(trainX, trainY,batch_size = 128, epochs = 20,\n",
        "                 validation_data=(validationX,validationY))\n",
        "    train_result.append(train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "705/705 [==============================] - 27s 37ms/step - loss: 0.1280 - accuracy: 0.2251 - val_loss: 0.0354 - val_accuracy: 0.7156\n",
            "Epoch 2/20\n",
            "705/705 [==============================] - 25s 36ms/step - loss: 0.0313 - accuracy: 0.7469 - val_loss: 0.0263 - val_accuracy: 0.7797\n",
            "Epoch 3/20\n",
            "705/705 [==============================] - 26s 36ms/step - loss: 0.0238 - accuracy: 0.8055 - val_loss: 0.0224 - val_accuracy: 0.8147\n",
            "Epoch 4/20\n",
            "705/705 [==============================] - 25s 36ms/step - loss: 0.0208 - accuracy: 0.8290 - val_loss: 0.0211 - val_accuracy: 0.8272\n",
            "Epoch 5/20\n",
            "705/705 [==============================] - 26s 36ms/step - loss: 0.0192 - accuracy: 0.8393 - val_loss: 0.0202 - val_accuracy: 0.8294\n",
            "Epoch 6/20\n",
            "705/705 [==============================] - 26s 36ms/step - loss: 0.0179 - accuracy: 0.8469 - val_loss: 0.0197 - val_accuracy: 0.8342\n",
            "Epoch 7/20\n",
            "705/705 [==============================] - 26s 36ms/step - loss: 0.0172 - accuracy: 0.8534 - val_loss: 0.0196 - val_accuracy: 0.8330\n",
            "Epoch 8/20\n",
            "705/705 [==============================] - 26s 36ms/step - loss: 0.0162 - accuracy: 0.8618 - val_loss: 0.0187 - val_accuracy: 0.8447\n",
            "Epoch 9/20\n",
            "705/705 [==============================] - 26s 36ms/step - loss: 0.0156 - accuracy: 0.8680 - val_loss: 0.0187 - val_accuracy: 0.8437\n",
            "Epoch 10/20\n",
            "705/705 [==============================] - 26s 36ms/step - loss: 0.0149 - accuracy: 0.8723 - val_loss: 0.0185 - val_accuracy: 0.8439\n",
            "Epoch 11/20\n",
            "705/705 [==============================] - 26s 37ms/step - loss: 0.0145 - accuracy: 0.8750 - val_loss: 0.0178 - val_accuracy: 0.8499\n",
            "Epoch 12/20\n",
            "705/705 [==============================] - 26s 37ms/step - loss: 0.0141 - accuracy: 0.8783 - val_loss: 0.0179 - val_accuracy: 0.8514\n",
            "Epoch 13/20\n",
            "705/705 [==============================] - 26s 37ms/step - loss: 0.0137 - accuracy: 0.8826 - val_loss: 0.0178 - val_accuracy: 0.8538\n",
            "Epoch 14/20\n",
            "705/705 [==============================] - 26s 37ms/step - loss: 0.0133 - accuracy: 0.8835 - val_loss: 0.0179 - val_accuracy: 0.8500\n",
            "Epoch 15/20\n",
            "705/705 [==============================] - 26s 37ms/step - loss: 0.0130 - accuracy: 0.8877 - val_loss: 0.0180 - val_accuracy: 0.8509\n",
            "Epoch 16/20\n",
            "705/705 [==============================] - 26s 37ms/step - loss: 0.0125 - accuracy: 0.8912 - val_loss: 0.0179 - val_accuracy: 0.8530\n",
            "Epoch 17/20\n",
            "705/705 [==============================] - 26s 37ms/step - loss: 0.0122 - accuracy: 0.8960 - val_loss: 0.0182 - val_accuracy: 0.8506\n",
            "Epoch 18/20\n",
            "705/705 [==============================] - 26s 37ms/step - loss: 0.0120 - accuracy: 0.8962 - val_loss: 0.0180 - val_accuracy: 0.8541\n",
            "Epoch 19/20\n",
            "705/705 [==============================] - 26s 37ms/step - loss: 0.0117 - accuracy: 0.8978 - val_loss: 0.0181 - val_accuracy: 0.8557\n",
            "Epoch 20/20\n",
            "705/705 [==============================] - 26s 37ms/step - loss: 0.0114 - accuracy: 0.9003 - val_loss: 0.0183 - val_accuracy: 0.8539\n",
            "Epoch 1/20\n",
            "705/705 [==============================] - 40s 56ms/step - loss: 0.1092 - accuracy: 0.3242 - val_loss: 0.0283 - val_accuracy: 0.7685\n",
            "Epoch 2/20\n",
            "705/705 [==============================] - 39s 55ms/step - loss: 0.0253 - accuracy: 0.7945 - val_loss: 0.0222 - val_accuracy: 0.8181\n",
            "Epoch 3/20\n",
            "705/705 [==============================] - 39s 55ms/step - loss: 0.0204 - accuracy: 0.8288 - val_loss: 0.0205 - val_accuracy: 0.8278\n",
            "Epoch 4/20\n",
            "705/705 [==============================] - 39s 55ms/step - loss: 0.0178 - accuracy: 0.8509 - val_loss: 0.0186 - val_accuracy: 0.8445\n",
            "Epoch 5/20\n",
            "705/705 [==============================] - 39s 55ms/step - loss: 0.0166 - accuracy: 0.8568 - val_loss: 0.0181 - val_accuracy: 0.8444\n",
            "Epoch 6/20\n",
            "705/705 [==============================] - 39s 55ms/step - loss: 0.0152 - accuracy: 0.8674 - val_loss: 0.0174 - val_accuracy: 0.8517\n",
            "Epoch 7/20\n",
            "705/705 [==============================] - 39s 55ms/step - loss: 0.0145 - accuracy: 0.8738 - val_loss: 0.0172 - val_accuracy: 0.8519\n",
            "Epoch 8/20\n",
            "705/705 [==============================] - 39s 56ms/step - loss: 0.0138 - accuracy: 0.8810 - val_loss: 0.0168 - val_accuracy: 0.8577\n",
            "Epoch 9/20\n",
            "705/705 [==============================] - 39s 55ms/step - loss: 0.0130 - accuracy: 0.8848 - val_loss: 0.0165 - val_accuracy: 0.8601\n",
            "Epoch 10/20\n",
            "705/705 [==============================] - 39s 55ms/step - loss: 0.0125 - accuracy: 0.8903 - val_loss: 0.0170 - val_accuracy: 0.8578\n",
            "Epoch 11/20\n",
            "705/705 [==============================] - 39s 55ms/step - loss: 0.0118 - accuracy: 0.8953 - val_loss: 0.0168 - val_accuracy: 0.8582\n",
            "Epoch 12/20\n",
            "705/705 [==============================] - 39s 55ms/step - loss: 0.0115 - accuracy: 0.8983 - val_loss: 0.0170 - val_accuracy: 0.8602\n",
            "Epoch 13/20\n",
            "705/705 [==============================] - 39s 55ms/step - loss: 0.0112 - accuracy: 0.9015 - val_loss: 0.0172 - val_accuracy: 0.8586\n",
            "Epoch 14/20\n",
            "705/705 [==============================] - 39s 56ms/step - loss: 0.0106 - accuracy: 0.9066 - val_loss: 0.0171 - val_accuracy: 0.8616\n",
            "Epoch 15/20\n",
            "705/705 [==============================] - 39s 55ms/step - loss: 0.0102 - accuracy: 0.9100 - val_loss: 0.0174 - val_accuracy: 0.8600\n",
            "Epoch 16/20\n",
            "705/705 [==============================] - 39s 56ms/step - loss: 0.0097 - accuracy: 0.9154 - val_loss: 0.0179 - val_accuracy: 0.8589\n",
            "Epoch 17/20\n",
            "705/705 [==============================] - 39s 56ms/step - loss: 0.0094 - accuracy: 0.9184 - val_loss: 0.0182 - val_accuracy: 0.8558\n",
            "Epoch 18/20\n",
            "705/705 [==============================] - 40s 57ms/step - loss: 0.0088 - accuracy: 0.9226 - val_loss: 0.0189 - val_accuracy: 0.8524\n",
            "Epoch 19/20\n",
            "705/705 [==============================] - 39s 56ms/step - loss: 0.0086 - accuracy: 0.9235 - val_loss: 0.0199 - val_accuracy: 0.8531\n",
            "Epoch 20/20\n",
            "705/705 [==============================] - 39s 56ms/step - loss: 0.0082 - accuracy: 0.9288 - val_loss: 0.0195 - val_accuracy: 0.8571\n",
            "Epoch 1/20\n",
            "705/705 [==============================] - 53s 74ms/step - loss: 0.0924 - accuracy: 0.3781 - val_loss: 0.0268 - val_accuracy: 0.7805\n",
            "Epoch 2/20\n",
            "705/705 [==============================] - 54s 77ms/step - loss: 0.0243 - accuracy: 0.8019 - val_loss: 0.0213 - val_accuracy: 0.8238\n",
            "Epoch 3/20\n",
            "705/705 [==============================] - 59s 84ms/step - loss: 0.0194 - accuracy: 0.8384 - val_loss: 0.0196 - val_accuracy: 0.8320\n",
            "Epoch 4/20\n",
            "705/705 [==============================] - 58s 83ms/step - loss: 0.0174 - accuracy: 0.8534 - val_loss: 0.0181 - val_accuracy: 0.8471\n",
            "Epoch 5/20\n",
            "705/705 [==============================] - 59s 83ms/step - loss: 0.0158 - accuracy: 0.8618 - val_loss: 0.0171 - val_accuracy: 0.8548\n",
            "Epoch 6/20\n",
            "705/705 [==============================] - 58s 82ms/step - loss: 0.0147 - accuracy: 0.8716 - val_loss: 0.0167 - val_accuracy: 0.8588\n",
            "Epoch 7/20\n",
            "705/705 [==============================] - 57s 81ms/step - loss: 0.0139 - accuracy: 0.8790 - val_loss: 0.0166 - val_accuracy: 0.8580\n",
            "Epoch 8/20\n",
            "705/705 [==============================] - 57s 81ms/step - loss: 0.0130 - accuracy: 0.8865 - val_loss: 0.0163 - val_accuracy: 0.8616\n",
            "Epoch 9/20\n",
            "705/705 [==============================] - 55s 78ms/step - loss: 0.0122 - accuracy: 0.8929 - val_loss: 0.0161 - val_accuracy: 0.8635\n",
            "Epoch 10/20\n",
            "705/705 [==============================] - 50s 71ms/step - loss: 0.0116 - accuracy: 0.8991 - val_loss: 0.0165 - val_accuracy: 0.8621\n",
            "Epoch 11/20\n",
            "705/705 [==============================] - 49s 70ms/step - loss: 0.0109 - accuracy: 0.9044 - val_loss: 0.0165 - val_accuracy: 0.8625\n",
            "Epoch 12/20\n",
            "705/705 [==============================] - 52s 74ms/step - loss: 0.0104 - accuracy: 0.9085 - val_loss: 0.0168 - val_accuracy: 0.8628\n",
            "Epoch 13/20\n",
            "705/705 [==============================] - 54s 76ms/step - loss: 0.0100 - accuracy: 0.9114 - val_loss: 0.0170 - val_accuracy: 0.8615\n",
            "Epoch 14/20\n",
            "705/705 [==============================] - 48s 67ms/step - loss: 0.0094 - accuracy: 0.9171 - val_loss: 0.0176 - val_accuracy: 0.8608\n",
            "Epoch 15/20\n",
            "705/705 [==============================] - 55s 77ms/step - loss: 0.0090 - accuracy: 0.9199 - val_loss: 0.0177 - val_accuracy: 0.8608\n",
            "Epoch 16/20\n",
            "705/705 [==============================] - 58s 82ms/step - loss: 0.0085 - accuracy: 0.9274 - val_loss: 0.0181 - val_accuracy: 0.8602\n",
            "Epoch 17/20\n",
            "705/705 [==============================] - 55s 78ms/step - loss: 0.0081 - accuracy: 0.9305 - val_loss: 0.0192 - val_accuracy: 0.8598\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 18/20\n",
            "705/705 [==============================] - 54s 76ms/step - loss: 0.0076 - accuracy: 0.9357 - val_loss: 0.0197 - val_accuracy: 0.8563\n",
            "Epoch 19/20\n",
            "705/705 [==============================] - 57s 81ms/step - loss: 0.0072 - accuracy: 0.9386 - val_loss: 0.0206 - val_accuracy: 0.8586\n",
            "Epoch 20/20\n",
            "705/705 [==============================] - 54s 77ms/step - loss: 0.0069 - accuracy: 0.9420 - val_loss: 0.0213 - val_accuracy: 0.8511\n",
            "Epoch 1/20\n",
            "705/705 [==============================] - 70s 98ms/step - loss: 0.0929 - accuracy: 0.3708 - val_loss: 0.0271 - val_accuracy: 0.7821\n",
            "Epoch 2/20\n",
            "705/705 [==============================] - 65s 92ms/step - loss: 0.0236 - accuracy: 0.8045 - val_loss: 0.0213 - val_accuracy: 0.8175\n",
            "Epoch 3/20\n",
            "705/705 [==============================] - 69s 98ms/step - loss: 0.0190 - accuracy: 0.8399 - val_loss: 0.0187 - val_accuracy: 0.8387\n",
            "Epoch 4/20\n",
            "705/705 [==============================] - 67s 95ms/step - loss: 0.0167 - accuracy: 0.8555 - val_loss: 0.0177 - val_accuracy: 0.8487\n",
            "Epoch 5/20\n",
            "705/705 [==============================] - 67s 96ms/step - loss: 0.0153 - accuracy: 0.8670 - val_loss: 0.0173 - val_accuracy: 0.8531\n",
            "Epoch 6/20\n",
            "705/705 [==============================] - 70s 100ms/step - loss: 0.0142 - accuracy: 0.8768 - val_loss: 0.0166 - val_accuracy: 0.8591\n",
            "Epoch 7/20\n",
            "705/705 [==============================] - 70s 100ms/step - loss: 0.0134 - accuracy: 0.8834 - val_loss: 0.0167 - val_accuracy: 0.8543\n",
            "Epoch 8/20\n",
            "705/705 [==============================] - 64s 90ms/step - loss: 0.0126 - accuracy: 0.8887 - val_loss: 0.0163 - val_accuracy: 0.8620\n",
            "Epoch 9/20\n",
            "705/705 [==============================] - 66s 94ms/step - loss: 0.0120 - accuracy: 0.8937 - val_loss: 0.0164 - val_accuracy: 0.8612\n",
            "Epoch 10/20\n",
            "705/705 [==============================] - 68s 97ms/step - loss: 0.0115 - accuracy: 0.8975 - val_loss: 0.0164 - val_accuracy: 0.8604\n",
            "Epoch 11/20\n",
            "705/705 [==============================] - 76s 108ms/step - loss: 0.0109 - accuracy: 0.9040 - val_loss: 0.0168 - val_accuracy: 0.8609\n",
            "Epoch 12/20\n",
            "705/705 [==============================] - 72s 102ms/step - loss: 0.0103 - accuracy: 0.9095 - val_loss: 0.0171 - val_accuracy: 0.8611\n",
            "Epoch 13/20\n",
            "705/705 [==============================] - 69s 98ms/step - loss: 0.0097 - accuracy: 0.9135 - val_loss: 0.0173 - val_accuracy: 0.8615\n",
            "Epoch 14/20\n",
            "705/705 [==============================] - 69s 98ms/step - loss: 0.0092 - accuracy: 0.9189 - val_loss: 0.0176 - val_accuracy: 0.8590\n",
            "Epoch 15/20\n",
            "705/705 [==============================] - 72s 102ms/step - loss: 0.0088 - accuracy: 0.9221 - val_loss: 0.0186 - val_accuracy: 0.8581\n",
            "Epoch 16/20\n",
            "705/705 [==============================] - 67s 95ms/step - loss: 0.0081 - accuracy: 0.9295 - val_loss: 0.0192 - val_accuracy: 0.8560\n",
            "Epoch 17/20\n",
            "705/705 [==============================] - 64s 90ms/step - loss: 0.0077 - accuracy: 0.9322 - val_loss: 0.0193 - val_accuracy: 0.8578\n",
            "Epoch 18/20\n",
            "705/705 [==============================] - 63s 90ms/step - loss: 0.0073 - accuracy: 0.9357 - val_loss: 0.0204 - val_accuracy: 0.8594\n",
            "Epoch 19/20\n",
            "705/705 [==============================] - 64s 90ms/step - loss: 0.0068 - accuracy: 0.9412 - val_loss: 0.0211 - val_accuracy: 0.8559\n",
            "Epoch 20/20\n",
            "705/705 [==============================] - 64s 91ms/step - loss: 0.0064 - accuracy: 0.9453 - val_loss: 0.0224 - val_accuracy: 0.8532\n",
            "Epoch 1/20\n",
            "705/705 [==============================] - 80s 113ms/step - loss: 0.0867 - accuracy: 0.4145 - val_loss: 0.0243 - val_accuracy: 0.8013\n",
            "Epoch 2/20\n",
            "705/705 [==============================] - 80s 113ms/step - loss: 0.0217 - accuracy: 0.8220 - val_loss: 0.0199 - val_accuracy: 0.8289\n",
            "Epoch 3/20\n",
            "705/705 [==============================] - 80s 113ms/step - loss: 0.0176 - accuracy: 0.8518 - val_loss: 0.0178 - val_accuracy: 0.8473\n",
            "Epoch 4/20\n",
            "705/705 [==============================] - 81s 115ms/step - loss: 0.0154 - accuracy: 0.8669 - val_loss: 0.0166 - val_accuracy: 0.8592\n",
            "Epoch 5/20\n",
            "705/705 [==============================] - 83s 118ms/step - loss: 0.0140 - accuracy: 0.8783 - val_loss: 0.0165 - val_accuracy: 0.8602\n",
            "Epoch 6/20\n",
            "705/705 [==============================] - 82s 117ms/step - loss: 0.0129 - accuracy: 0.8874 - val_loss: 0.0160 - val_accuracy: 0.8621\n",
            "Epoch 7/20\n",
            "705/705 [==============================] - 82s 117ms/step - loss: 0.0122 - accuracy: 0.8930 - val_loss: 0.0162 - val_accuracy: 0.8620\n",
            "Epoch 8/20\n",
            "705/705 [==============================] - 89s 127ms/step - loss: 0.0114 - accuracy: 0.8988 - val_loss: 0.0161 - val_accuracy: 0.8646\n",
            "Epoch 9/20\n",
            "705/705 [==============================] - 94s 134ms/step - loss: 0.0106 - accuracy: 0.9062 - val_loss: 0.0162 - val_accuracy: 0.8657\n",
            "Epoch 10/20\n",
            "705/705 [==============================] - 85s 121ms/step - loss: 0.0101 - accuracy: 0.9099 - val_loss: 0.0169 - val_accuracy: 0.8630\n",
            "Epoch 11/20\n",
            "705/705 [==============================] - 80s 114ms/step - loss: 0.0093 - accuracy: 0.9178 - val_loss: 0.0167 - val_accuracy: 0.8663\n",
            "Epoch 12/20\n",
            "705/705 [==============================] - 80s 114ms/step - loss: 0.0087 - accuracy: 0.9229 - val_loss: 0.0178 - val_accuracy: 0.8609\n",
            "Epoch 13/20\n",
            "705/705 [==============================] - 80s 113ms/step - loss: 0.0081 - accuracy: 0.9283 - val_loss: 0.0183 - val_accuracy: 0.8627\n",
            "Epoch 14/20\n",
            "705/705 [==============================] - 80s 114ms/step - loss: 0.0075 - accuracy: 0.9350 - val_loss: 0.0189 - val_accuracy: 0.8619\n",
            "Epoch 15/20\n",
            "705/705 [==============================] - 80s 114ms/step - loss: 0.0070 - accuracy: 0.9387 - val_loss: 0.0207 - val_accuracy: 0.8596\n",
            "Epoch 16/20\n",
            "705/705 [==============================] - 80s 113ms/step - loss: 0.0064 - accuracy: 0.9437 - val_loss: 0.0214 - val_accuracy: 0.8555\n",
            "Epoch 17/20\n",
            "705/705 [==============================] - 80s 114ms/step - loss: 0.0060 - accuracy: 0.9484 - val_loss: 0.0214 - val_accuracy: 0.8567\n",
            "Epoch 18/20\n",
            "705/705 [==============================] - 79s 113ms/step - loss: 0.0055 - accuracy: 0.9525 - val_loss: 0.0231 - val_accuracy: 0.8573\n",
            "Epoch 19/20\n",
            "705/705 [==============================] - 80s 114ms/step - loss: 0.0052 - accuracy: 0.9566 - val_loss: 0.0246 - val_accuracy: 0.8574\n",
            "Epoch 20/20\n",
            "705/705 [==============================] - 80s 114ms/step - loss: 0.0048 - accuracy: 0.9586 - val_loss: 0.0263 - val_accuracy: 0.8536\n",
            "Epoch 1/20\n",
            "705/705 [==============================] - 98s 138ms/step - loss: 0.0859 - accuracy: 0.4116 - val_loss: 0.0244 - val_accuracy: 0.8020\n",
            "Epoch 2/20\n",
            "705/705 [==============================] - 97s 138ms/step - loss: 0.0224 - accuracy: 0.8149 - val_loss: 0.0197 - val_accuracy: 0.8359\n",
            "Epoch 3/20\n",
            "705/705 [==============================] - 97s 138ms/step - loss: 0.0178 - accuracy: 0.8495 - val_loss: 0.0181 - val_accuracy: 0.8449\n",
            "Epoch 4/20\n",
            "705/705 [==============================] - 98s 139ms/step - loss: 0.0154 - accuracy: 0.8666 - val_loss: 0.0169 - val_accuracy: 0.8558\n",
            "Epoch 5/20\n",
            "705/705 [==============================] - 98s 138ms/step - loss: 0.0141 - accuracy: 0.8767 - val_loss: 0.0165 - val_accuracy: 0.8570\n",
            "Epoch 6/20\n",
            "705/705 [==============================] - 97s 138ms/step - loss: 0.0131 - accuracy: 0.8839 - val_loss: 0.0160 - val_accuracy: 0.8646\n",
            "Epoch 7/20\n",
            "705/705 [==============================] - 101s 144ms/step - loss: 0.0122 - accuracy: 0.8935 - val_loss: 0.0160 - val_accuracy: 0.8645\n",
            "Epoch 8/20\n",
            "705/705 [==============================] - 97s 138ms/step - loss: 0.0114 - accuracy: 0.8999 - val_loss: 0.0157 - val_accuracy: 0.8672\n",
            "Epoch 9/20\n",
            "705/705 [==============================] - 97s 138ms/step - loss: 0.0107 - accuracy: 0.9076 - val_loss: 0.0161 - val_accuracy: 0.8665\n",
            "Epoch 10/20\n",
            "705/705 [==============================] - 97s 138ms/step - loss: 0.0101 - accuracy: 0.9091 - val_loss: 0.0167 - val_accuracy: 0.8626\n",
            "Epoch 11/20\n",
            "705/705 [==============================] - 98s 138ms/step - loss: 0.0094 - accuracy: 0.9172 - val_loss: 0.0168 - val_accuracy: 0.8647\n",
            "Epoch 12/20\n",
            "705/705 [==============================] - 97s 138ms/step - loss: 0.0087 - accuracy: 0.9216 - val_loss: 0.0176 - val_accuracy: 0.8642\n",
            "Epoch 13/20\n",
            "705/705 [==============================] - 97s 138ms/step - loss: 0.0081 - accuracy: 0.9276 - val_loss: 0.0184 - val_accuracy: 0.8622\n",
            "Epoch 14/20\n",
            "705/705 [==============================] - 95s 135ms/step - loss: 0.0074 - accuracy: 0.9350 - val_loss: 0.0191 - val_accuracy: 0.8589\n",
            "Epoch 15/20\n",
            "705/705 [==============================] - 98s 139ms/step - loss: 0.0069 - accuracy: 0.9395 - val_loss: 0.0196 - val_accuracy: 0.8632\n",
            "Epoch 16/20\n",
            "705/705 [==============================] - 96s 136ms/step - loss: 0.0064 - accuracy: 0.9443 - val_loss: 0.0211 - val_accuracy: 0.8596\n",
            "Epoch 17/20\n",
            "705/705 [==============================] - 95s 135ms/step - loss: 0.0058 - accuracy: 0.9503 - val_loss: 0.0221 - val_accuracy: 0.8547\n",
            "Epoch 18/20\n",
            "705/705 [==============================] - 95s 135ms/step - loss: 0.0054 - accuracy: 0.9550 - val_loss: 0.0236 - val_accuracy: 0.8561\n",
            "Epoch 19/20\n",
            "705/705 [==============================] - 96s 136ms/step - loss: 0.0050 - accuracy: 0.9587 - val_loss: 0.0251 - val_accuracy: 0.8566\n",
            "Epoch 20/20\n",
            "705/705 [==============================] - 96s 136ms/step - loss: 0.0047 - accuracy: 0.9603 - val_loss: 0.0269 - val_accuracy: 0.8539\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NAfx4MwvLPQi",
        "outputId": "99677bfc-f4f8-42b7-e20a-4b69f7154189"
      },
      "source": [
        "print(np.mean(train_result[0].history['accuracy']))\n",
        "print(np.mean(train_result[1].history['accuracy']))\n",
        "print(np.mean(train_result[2].history['accuracy']))\n",
        "print(np.mean(train_result[3].history['accuracy']))\n",
        "print(np.mean(train_result[4].history['accuracy']))\n",
        "print(np.mean(train_result[5].history['accuracy']))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8432651773095131\n",
            "0.8691278785467148\n",
            "0.8798409789800644\n",
            "0.8815209448337555\n",
            "0.8951562494039536\n",
            "0.8958732336759567\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pOPdAdtpLPQi"
      },
      "source": [
        "#Experiment 3 \n",
        "nets = 8\n",
        "model = [0] *nets\n",
        "\n",
        "for j in range(8):\n",
        "    model[j] = Sequential()\n",
        "    model[j].add(Conv2D(24,kernel_size=5,activation='relu',input_shape=(28,28,1)))\n",
        "    model[j].add(MaxPool2D())\n",
        "    model[j].add(Conv2D(48,kernel_size=5,activation='relu'))\n",
        "    model[j].add(MaxPool2D())\n",
        "    model[j].add(Flatten())\n",
        "    if j>0:\n",
        "        model[j].add(Dense(2**(j+4), activation='relu'))\n",
        "    model[j].add(Dense(47, activation='sigmoid'))\n",
        "    model[j].compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "75blV6_ILPQk",
        "outputId": "f9e50a58-4e5c-41f2-9e83-eed4ec722fa2"
      },
      "source": [
        "train_result = []\n",
        "for i in range (8):\n",
        "    train = model[i].fit(trainX, trainY,batch_size = 128, epochs = 20,\n",
        "                 validation_data=(validationX,validationY))\n",
        "    train_result.append(train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "705/705 [==============================] - 52s 73ms/step - loss: 0.0982 - accuracy: 0.3448 - val_loss: 0.0302 - val_accuracy: 0.7664\n",
            "Epoch 2/20\n",
            "705/705 [==============================] - 57s 81ms/step - loss: 0.0278 - accuracy: 0.7847 - val_loss: 0.0248 - val_accuracy: 0.8074\n",
            "Epoch 3/20\n",
            "705/705 [==============================] - 62s 88ms/step - loss: 0.0231 - accuracy: 0.8210 - val_loss: 0.0224 - val_accuracy: 0.8255\n",
            "Epoch 4/20\n",
            "705/705 [==============================] - 57s 80ms/step - loss: 0.0208 - accuracy: 0.8353 - val_loss: 0.0212 - val_accuracy: 0.8318\n",
            "Epoch 5/20\n",
            "705/705 [==============================] - 53s 75ms/step - loss: 0.0195 - accuracy: 0.8455 - val_loss: 0.0204 - val_accuracy: 0.8399\n",
            "Epoch 6/20\n",
            "705/705 [==============================] - 56s 79ms/step - loss: 0.0183 - accuracy: 0.8537 - val_loss: 0.0198 - val_accuracy: 0.8431\n",
            "Epoch 7/20\n",
            "705/705 [==============================] - 53s 75ms/step - loss: 0.0174 - accuracy: 0.8612 - val_loss: 0.0190 - val_accuracy: 0.8480\n",
            "Epoch 8/20\n",
            "705/705 [==============================] - 53s 75ms/step - loss: 0.0167 - accuracy: 0.8657 - val_loss: 0.0186 - val_accuracy: 0.8502\n",
            "Epoch 9/20\n",
            "705/705 [==============================] - 55s 78ms/step - loss: 0.0160 - accuracy: 0.8727 - val_loss: 0.0187 - val_accuracy: 0.8518\n",
            "Epoch 10/20\n",
            "705/705 [==============================] - 55s 78ms/step - loss: 0.0157 - accuracy: 0.8743 - val_loss: 0.0185 - val_accuracy: 0.8516\n",
            "Epoch 11/20\n",
            "705/705 [==============================] - 55s 78ms/step - loss: 0.0151 - accuracy: 0.8783 - val_loss: 0.0186 - val_accuracy: 0.8516\n",
            "Epoch 12/20\n",
            "705/705 [==============================] - 55s 79ms/step - loss: 0.0147 - accuracy: 0.8825 - val_loss: 0.0186 - val_accuracy: 0.8526\n",
            "Epoch 13/20\n",
            "705/705 [==============================] - 60s 84ms/step - loss: 0.0145 - accuracy: 0.8828 - val_loss: 0.0180 - val_accuracy: 0.8539\n",
            "Epoch 14/20\n",
            "705/705 [==============================] - 55s 78ms/step - loss: 0.0143 - accuracy: 0.8858 - val_loss: 0.0181 - val_accuracy: 0.8570\n",
            "Epoch 15/20\n",
            "705/705 [==============================] - 54s 77ms/step - loss: 0.0138 - accuracy: 0.8889 - val_loss: 0.0183 - val_accuracy: 0.8595\n",
            "Epoch 16/20\n",
            "705/705 [==============================] - 58s 82ms/step - loss: 0.0134 - accuracy: 0.8927 - val_loss: 0.0184 - val_accuracy: 0.8583\n",
            "Epoch 17/20\n",
            "705/705 [==============================] - 64s 90ms/step - loss: 0.0130 - accuracy: 0.8961 - val_loss: 0.0186 - val_accuracy: 0.8522\n",
            "Epoch 18/20\n",
            "705/705 [==============================] - 52s 74ms/step - loss: 0.0130 - accuracy: 0.8963 - val_loss: 0.0185 - val_accuracy: 0.8529\n",
            "Epoch 19/20\n",
            "705/705 [==============================] - 55s 78ms/step - loss: 0.0127 - accuracy: 0.8984 - val_loss: 0.0185 - val_accuracy: 0.8580\n",
            "Epoch 20/20\n",
            "705/705 [==============================] - 57s 81ms/step - loss: 0.0123 - accuracy: 0.9028 - val_loss: 0.0189 - val_accuracy: 0.8549\n",
            "Epoch 1/20\n",
            "705/705 [==============================] - 58s 81ms/step - loss: 0.1589 - accuracy: 0.2144 - val_loss: 0.0445 - val_accuracy: 0.6495\n",
            "Epoch 2/20\n",
            "705/705 [==============================] - 57s 81ms/step - loss: 0.0404 - accuracy: 0.6897 - val_loss: 0.0343 - val_accuracy: 0.7360\n",
            "Epoch 3/20\n",
            "705/705 [==============================] - 53s 76ms/step - loss: 0.0324 - accuracy: 0.7515 - val_loss: 0.0301 - val_accuracy: 0.7728\n",
            "Epoch 4/20\n",
            "705/705 [==============================] - 54s 76ms/step - loss: 0.0280 - accuracy: 0.7877 - val_loss: 0.0269 - val_accuracy: 0.7919\n",
            "Epoch 5/20\n",
            "705/705 [==============================] - 53s 76ms/step - loss: 0.0259 - accuracy: 0.7996 - val_loss: 0.0257 - val_accuracy: 0.8040\n",
            "Epoch 6/20\n",
            "705/705 [==============================] - 53s 76ms/step - loss: 0.0242 - accuracy: 0.8119 - val_loss: 0.0242 - val_accuracy: 0.8112\n",
            "Epoch 7/20\n",
            "705/705 [==============================] - 54s 77ms/step - loss: 0.0229 - accuracy: 0.8211 - val_loss: 0.0234 - val_accuracy: 0.8112\n",
            "Epoch 8/20\n",
            "705/705 [==============================] - 53s 76ms/step - loss: 0.0220 - accuracy: 0.8266 - val_loss: 0.0228 - val_accuracy: 0.8207\n",
            "Epoch 9/20\n",
            "705/705 [==============================] - 56s 80ms/step - loss: 0.0214 - accuracy: 0.8329 - val_loss: 0.0227 - val_accuracy: 0.8244\n",
            "Epoch 10/20\n",
            "705/705 [==============================] - 61s 87ms/step - loss: 0.0205 - accuracy: 0.8394 - val_loss: 0.0220 - val_accuracy: 0.8273\n",
            "Epoch 11/20\n",
            "705/705 [==============================] - 55s 78ms/step - loss: 0.0203 - accuracy: 0.8410 - val_loss: 0.0219 - val_accuracy: 0.8311\n",
            "Epoch 12/20\n",
            "705/705 [==============================] - 54s 77ms/step - loss: 0.0200 - accuracy: 0.8414 - val_loss: 0.0215 - val_accuracy: 0.8314\n",
            "Epoch 13/20\n",
            "705/705 [==============================] - 54s 76ms/step - loss: 0.0194 - accuracy: 0.8458 - val_loss: 0.0213 - val_accuracy: 0.8337\n",
            "Epoch 14/20\n",
            "705/705 [==============================] - 53s 76ms/step - loss: 0.0189 - accuracy: 0.8507 - val_loss: 0.0210 - val_accuracy: 0.8332\n",
            "Epoch 15/20\n",
            "705/705 [==============================] - 54s 76ms/step - loss: 0.0188 - accuracy: 0.8517 - val_loss: 0.0208 - val_accuracy: 0.8329\n",
            "Epoch 16/20\n",
            "705/705 [==============================] - 55s 77ms/step - loss: 0.0184 - accuracy: 0.8527 - val_loss: 0.0203 - val_accuracy: 0.8400\n",
            "Epoch 17/20\n",
            "705/705 [==============================] - 54s 76ms/step - loss: 0.0180 - accuracy: 0.8554 - val_loss: 0.0203 - val_accuracy: 0.8402\n",
            "Epoch 18/20\n",
            "705/705 [==============================] - 54s 76ms/step - loss: 0.0179 - accuracy: 0.8582 - val_loss: 0.0209 - val_accuracy: 0.8375\n",
            "Epoch 19/20\n",
            "705/705 [==============================] - 54s 76ms/step - loss: 0.0177 - accuracy: 0.8594 - val_loss: 0.0203 - val_accuracy: 0.8398\n",
            "Epoch 20/20\n",
            "705/705 [==============================] - 54s 77ms/step - loss: 0.0173 - accuracy: 0.8610 - val_loss: 0.0202 - val_accuracy: 0.8394\n",
            "Epoch 1/20\n",
            "705/705 [==============================] - 54s 76ms/step - loss: 0.1214 - accuracy: 0.2061 - val_loss: 0.0417 - val_accuracy: 0.6547\n",
            "Epoch 2/20\n",
            "705/705 [==============================] - 54s 76ms/step - loss: 0.0371 - accuracy: 0.7036 - val_loss: 0.0301 - val_accuracy: 0.7667\n",
            "Epoch 3/20\n",
            "705/705 [==============================] - 53s 76ms/step - loss: 0.0282 - accuracy: 0.7773 - val_loss: 0.0260 - val_accuracy: 0.7949\n",
            "Epoch 4/20\n",
            "705/705 [==============================] - 53s 75ms/step - loss: 0.0245 - accuracy: 0.8049 - val_loss: 0.0234 - val_accuracy: 0.8167\n",
            "Epoch 5/20\n",
            "705/705 [==============================] - 53s 75ms/step - loss: 0.0221 - accuracy: 0.8223 - val_loss: 0.0223 - val_accuracy: 0.8195\n",
            "Epoch 6/20\n",
            "705/705 [==============================] - 53s 75ms/step - loss: 0.0205 - accuracy: 0.8337 - val_loss: 0.0212 - val_accuracy: 0.8279\n",
            "Epoch 7/20\n",
            "705/705 [==============================] - 53s 75ms/step - loss: 0.0196 - accuracy: 0.8409 - val_loss: 0.0203 - val_accuracy: 0.8367\n",
            "Epoch 8/20\n",
            "705/705 [==============================] - 54s 76ms/step - loss: 0.0187 - accuracy: 0.8489 - val_loss: 0.0200 - val_accuracy: 0.8394\n",
            "Epoch 9/20\n",
            "705/705 [==============================] - 53s 75ms/step - loss: 0.0181 - accuracy: 0.8505 - val_loss: 0.0195 - val_accuracy: 0.8402\n",
            "Epoch 10/20\n",
            "705/705 [==============================] - 54s 76ms/step - loss: 0.0172 - accuracy: 0.8570 - val_loss: 0.0198 - val_accuracy: 0.8355\n",
            "Epoch 11/20\n",
            "705/705 [==============================] - 53s 76ms/step - loss: 0.0167 - accuracy: 0.8639 - val_loss: 0.0189 - val_accuracy: 0.8453\n",
            "Epoch 12/20\n",
            "705/705 [==============================] - 53s 76ms/step - loss: 0.0163 - accuracy: 0.8641 - val_loss: 0.0186 - val_accuracy: 0.8491\n",
            "Epoch 13/20\n",
            "705/705 [==============================] - 53s 76ms/step - loss: 0.0157 - accuracy: 0.8687 - val_loss: 0.0185 - val_accuracy: 0.8489\n",
            "Epoch 14/20\n",
            "705/705 [==============================] - 54s 76ms/step - loss: 0.0153 - accuracy: 0.8716 - val_loss: 0.0184 - val_accuracy: 0.8498\n",
            "Epoch 15/20\n",
            "705/705 [==============================] - 54s 76ms/step - loss: 0.0151 - accuracy: 0.8741 - val_loss: 0.0181 - val_accuracy: 0.8513\n",
            "Epoch 16/20\n",
            "705/705 [==============================] - 58s 82ms/step - loss: 0.0148 - accuracy: 0.8774 - val_loss: 0.0179 - val_accuracy: 0.8510\n",
            "Epoch 17/20\n",
            "705/705 [==============================] - 53s 76ms/step - loss: 0.0143 - accuracy: 0.8788 - val_loss: 0.0178 - val_accuracy: 0.8534\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 18/20\n",
            "705/705 [==============================] - 50s 71ms/step - loss: 0.0141 - accuracy: 0.8809 - val_loss: 0.0177 - val_accuracy: 0.8544\n",
            "Epoch 19/20\n",
            "705/705 [==============================] - 50s 72ms/step - loss: 0.0139 - accuracy: 0.8830 - val_loss: 0.0176 - val_accuracy: 0.8552\n",
            "Epoch 20/20\n",
            "705/705 [==============================] - 52s 73ms/step - loss: 0.0136 - accuracy: 0.8851 - val_loss: 0.0178 - val_accuracy: 0.8566\n",
            "Epoch 1/20\n",
            "705/705 [==============================] - 52s 73ms/step - loss: 0.1077 - accuracy: 0.3202 - val_loss: 0.0311 - val_accuracy: 0.7531\n",
            "Epoch 2/20\n",
            "705/705 [==============================] - 51s 73ms/step - loss: 0.0277 - accuracy: 0.7773 - val_loss: 0.0235 - val_accuracy: 0.8070\n",
            "Epoch 3/20\n",
            "705/705 [==============================] - 51s 72ms/step - loss: 0.0216 - accuracy: 0.8238 - val_loss: 0.0209 - val_accuracy: 0.8246\n",
            "Epoch 4/20\n",
            "705/705 [==============================] - 52s 74ms/step - loss: 0.0193 - accuracy: 0.8397 - val_loss: 0.0198 - val_accuracy: 0.8349\n",
            "Epoch 5/20\n",
            "705/705 [==============================] - 51s 73ms/step - loss: 0.0177 - accuracy: 0.8512 - val_loss: 0.0188 - val_accuracy: 0.8445\n",
            "Epoch 6/20\n",
            "705/705 [==============================] - 51s 73ms/step - loss: 0.0165 - accuracy: 0.8612 - val_loss: 0.0183 - val_accuracy: 0.8468\n",
            "Epoch 7/20\n",
            "705/705 [==============================] - 51s 73ms/step - loss: 0.0159 - accuracy: 0.8646 - val_loss: 0.0176 - val_accuracy: 0.8514\n",
            "Epoch 8/20\n",
            "705/705 [==============================] - 51s 73ms/step - loss: 0.0148 - accuracy: 0.8722 - val_loss: 0.0176 - val_accuracy: 0.8511\n",
            "Epoch 9/20\n",
            "705/705 [==============================] - 51s 73ms/step - loss: 0.0144 - accuracy: 0.8774 - val_loss: 0.0171 - val_accuracy: 0.8578\n",
            "Epoch 10/20\n",
            "705/705 [==============================] - 51s 73ms/step - loss: 0.0139 - accuracy: 0.8809 - val_loss: 0.0170 - val_accuracy: 0.8578\n",
            "Epoch 11/20\n",
            "705/705 [==============================] - 52s 73ms/step - loss: 0.0132 - accuracy: 0.8857 - val_loss: 0.0172 - val_accuracy: 0.8585\n",
            "Epoch 12/20\n",
            "705/705 [==============================] - 52s 73ms/step - loss: 0.0127 - accuracy: 0.8906 - val_loss: 0.0171 - val_accuracy: 0.8578\n",
            "Epoch 13/20\n",
            "705/705 [==============================] - 52s 74ms/step - loss: 0.0125 - accuracy: 0.8914 - val_loss: 0.0167 - val_accuracy: 0.8591\n",
            "Epoch 14/20\n",
            "705/705 [==============================] - 52s 74ms/step - loss: 0.0121 - accuracy: 0.8960 - val_loss: 0.0172 - val_accuracy: 0.8586\n",
            "Epoch 15/20\n",
            "705/705 [==============================] - 51s 73ms/step - loss: 0.0117 - accuracy: 0.8979 - val_loss: 0.0171 - val_accuracy: 0.8590\n",
            "Epoch 16/20\n",
            "705/705 [==============================] - 52s 73ms/step - loss: 0.0115 - accuracy: 0.8991 - val_loss: 0.0170 - val_accuracy: 0.8617\n",
            "Epoch 17/20\n",
            "705/705 [==============================] - 51s 73ms/step - loss: 0.0111 - accuracy: 0.9028 - val_loss: 0.0174 - val_accuracy: 0.8583\n",
            "Epoch 18/20\n",
            "705/705 [==============================] - 52s 73ms/step - loss: 0.0108 - accuracy: 0.9064 - val_loss: 0.0177 - val_accuracy: 0.8588\n",
            "Epoch 19/20\n",
            "705/705 [==============================] - 52s 74ms/step - loss: 0.0106 - accuracy: 0.9076 - val_loss: 0.0179 - val_accuracy: 0.8548\n",
            "Epoch 20/20\n",
            "705/705 [==============================] - 52s 73ms/step - loss: 0.0101 - accuracy: 0.9127 - val_loss: 0.0181 - val_accuracy: 0.8578\n",
            "Epoch 1/20\n",
            "705/705 [==============================] - 53s 75ms/step - loss: 0.0926 - accuracy: 0.3813 - val_loss: 0.0281 - val_accuracy: 0.7719\n",
            "Epoch 2/20\n",
            "705/705 [==============================] - 53s 75ms/step - loss: 0.0253 - accuracy: 0.7947 - val_loss: 0.0222 - val_accuracy: 0.8192\n",
            "Epoch 3/20\n",
            "705/705 [==============================] - 53s 75ms/step - loss: 0.0202 - accuracy: 0.8311 - val_loss: 0.0200 - val_accuracy: 0.8301\n",
            "Epoch 4/20\n",
            "705/705 [==============================] - 53s 74ms/step - loss: 0.0175 - accuracy: 0.8506 - val_loss: 0.0187 - val_accuracy: 0.8445\n",
            "Epoch 5/20\n",
            "705/705 [==============================] - 53s 75ms/step - loss: 0.0160 - accuracy: 0.8635 - val_loss: 0.0174 - val_accuracy: 0.8522\n",
            "Epoch 6/20\n",
            "705/705 [==============================] - 53s 74ms/step - loss: 0.0152 - accuracy: 0.8679 - val_loss: 0.0172 - val_accuracy: 0.8546\n",
            "Epoch 7/20\n",
            "705/705 [==============================] - 53s 75ms/step - loss: 0.0138 - accuracy: 0.8824 - val_loss: 0.0168 - val_accuracy: 0.8542\n",
            "Epoch 8/20\n",
            "705/705 [==============================] - 53s 74ms/step - loss: 0.0132 - accuracy: 0.8851 - val_loss: 0.0165 - val_accuracy: 0.8592\n",
            "Epoch 9/20\n",
            "705/705 [==============================] - 53s 75ms/step - loss: 0.0123 - accuracy: 0.8925 - val_loss: 0.0170 - val_accuracy: 0.8553\n",
            "Epoch 10/20\n",
            "705/705 [==============================] - 53s 75ms/step - loss: 0.0118 - accuracy: 0.8950 - val_loss: 0.0167 - val_accuracy: 0.8604\n",
            "Epoch 11/20\n",
            "705/705 [==============================] - 53s 75ms/step - loss: 0.0112 - accuracy: 0.9013 - val_loss: 0.0169 - val_accuracy: 0.8587\n",
            "Epoch 12/20\n",
            "705/705 [==============================] - 53s 75ms/step - loss: 0.0106 - accuracy: 0.9070 - val_loss: 0.0170 - val_accuracy: 0.8568\n",
            "Epoch 13/20\n",
            "705/705 [==============================] - 53s 75ms/step - loss: 0.0101 - accuracy: 0.9098 - val_loss: 0.0174 - val_accuracy: 0.8594\n",
            "Epoch 14/20\n",
            "705/705 [==============================] - 53s 75ms/step - loss: 0.0093 - accuracy: 0.9173 - val_loss: 0.0175 - val_accuracy: 0.8617\n",
            "Epoch 15/20\n",
            "705/705 [==============================] - 53s 75ms/step - loss: 0.0091 - accuracy: 0.9190 - val_loss: 0.0187 - val_accuracy: 0.8595\n",
            "Epoch 16/20\n",
            "705/705 [==============================] - 53s 75ms/step - loss: 0.0086 - accuracy: 0.9258 - val_loss: 0.0185 - val_accuracy: 0.8570\n",
            "Epoch 17/20\n",
            "705/705 [==============================] - 53s 75ms/step - loss: 0.0079 - accuracy: 0.9311 - val_loss: 0.0196 - val_accuracy: 0.8555\n",
            "Epoch 18/20\n",
            "705/705 [==============================] - 53s 75ms/step - loss: 0.0076 - accuracy: 0.9334 - val_loss: 0.0202 - val_accuracy: 0.8569\n",
            "Epoch 19/20\n",
            "705/705 [==============================] - 53s 75ms/step - loss: 0.0073 - accuracy: 0.9361 - val_loss: 0.0209 - val_accuracy: 0.8527\n",
            "Epoch 20/20\n",
            "705/705 [==============================] - 53s 75ms/step - loss: 0.0068 - accuracy: 0.9409 - val_loss: 0.0218 - val_accuracy: 0.8506\n",
            "Epoch 1/20\n",
            "705/705 [==============================] - 57s 79ms/step - loss: 0.0924 - accuracy: 0.3673 - val_loss: 0.0252 - val_accuracy: 0.7931\n",
            "Epoch 2/20\n",
            "705/705 [==============================] - 56s 79ms/step - loss: 0.0224 - accuracy: 0.8117 - val_loss: 0.0196 - val_accuracy: 0.8332\n",
            "Epoch 3/20\n",
            "705/705 [==============================] - 56s 80ms/step - loss: 0.0180 - accuracy: 0.8458 - val_loss: 0.0182 - val_accuracy: 0.8455\n",
            "Epoch 4/20\n",
            "705/705 [==============================] - 56s 80ms/step - loss: 0.0158 - accuracy: 0.8636 - val_loss: 0.0169 - val_accuracy: 0.8553\n",
            "Epoch 5/20\n",
            "705/705 [==============================] - 56s 80ms/step - loss: 0.0146 - accuracy: 0.8724 - val_loss: 0.0167 - val_accuracy: 0.8565\n",
            "Epoch 6/20\n",
            "705/705 [==============================] - 56s 79ms/step - loss: 0.0131 - accuracy: 0.8844 - val_loss: 0.0168 - val_accuracy: 0.8584\n",
            "Epoch 7/20\n",
            "705/705 [==============================] - 56s 80ms/step - loss: 0.0125 - accuracy: 0.8895 - val_loss: 0.0164 - val_accuracy: 0.8589\n",
            "Epoch 8/20\n",
            "705/705 [==============================] - 56s 80ms/step - loss: 0.0116 - accuracy: 0.8969 - val_loss: 0.0167 - val_accuracy: 0.8596\n",
            "Epoch 9/20\n",
            "705/705 [==============================] - 55s 78ms/step - loss: 0.0108 - accuracy: 0.9036 - val_loss: 0.0165 - val_accuracy: 0.8605\n",
            "Epoch 10/20\n",
            "705/705 [==============================] - 55s 77ms/step - loss: 0.0100 - accuracy: 0.9104 - val_loss: 0.0170 - val_accuracy: 0.8623\n",
            "Epoch 11/20\n",
            "705/705 [==============================] - 55s 77ms/step - loss: 0.0093 - accuracy: 0.9166 - val_loss: 0.0175 - val_accuracy: 0.8629\n",
            "Epoch 12/20\n",
            "705/705 [==============================] - 55s 77ms/step - loss: 0.0086 - accuracy: 0.9230 - val_loss: 0.0182 - val_accuracy: 0.8601\n",
            "Epoch 13/20\n",
            "705/705 [==============================] - 56s 79ms/step - loss: 0.0079 - accuracy: 0.9293 - val_loss: 0.0186 - val_accuracy: 0.8617\n",
            "Epoch 14/20\n",
            "705/705 [==============================] - 56s 80ms/step - loss: 0.0072 - accuracy: 0.9367 - val_loss: 0.0200 - val_accuracy: 0.8574\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 15/20\n",
            "705/705 [==============================] - 55s 78ms/step - loss: 0.0068 - accuracy: 0.9397 - val_loss: 0.0211 - val_accuracy: 0.8565\n",
            "Epoch 16/20\n",
            "705/705 [==============================] - 55s 78ms/step - loss: 0.0063 - accuracy: 0.9448 - val_loss: 0.0217 - val_accuracy: 0.8579\n",
            "Epoch 17/20\n",
            "705/705 [==============================] - 55s 78ms/step - loss: 0.0057 - accuracy: 0.9500 - val_loss: 0.0231 - val_accuracy: 0.8551\n",
            "Epoch 18/20\n",
            "705/705 [==============================] - 56s 80ms/step - loss: 0.0053 - accuracy: 0.9531 - val_loss: 0.0253 - val_accuracy: 0.8493\n",
            "Epoch 19/20\n",
            "705/705 [==============================] - 54s 76ms/step - loss: 0.0050 - accuracy: 0.9562 - val_loss: 0.0261 - val_accuracy: 0.8516\n",
            "Epoch 20/20\n",
            "705/705 [==============================] - 54s 76ms/step - loss: 0.0048 - accuracy: 0.9588 - val_loss: 0.0273 - val_accuracy: 0.8508\n",
            "Epoch 1/20\n",
            "705/705 [==============================] - 59s 83ms/step - loss: 0.0846 - accuracy: 0.4145 - val_loss: 0.0237 - val_accuracy: 0.8056\n",
            "Epoch 2/20\n",
            "705/705 [==============================] - 58s 83ms/step - loss: 0.0209 - accuracy: 0.8231 - val_loss: 0.0187 - val_accuracy: 0.8416\n",
            "Epoch 3/20\n",
            "705/705 [==============================] - 60s 86ms/step - loss: 0.0167 - accuracy: 0.8534 - val_loss: 0.0173 - val_accuracy: 0.8500\n",
            "Epoch 4/20\n",
            "705/705 [==============================] - 60s 85ms/step - loss: 0.0149 - accuracy: 0.8696 - val_loss: 0.0170 - val_accuracy: 0.8531\n",
            "Epoch 5/20\n",
            "705/705 [==============================] - 59s 84ms/step - loss: 0.0134 - accuracy: 0.8817 - val_loss: 0.0163 - val_accuracy: 0.8551\n",
            "Epoch 6/20\n",
            "705/705 [==============================] - 59s 83ms/step - loss: 0.0121 - accuracy: 0.8904 - val_loss: 0.0156 - val_accuracy: 0.8650\n",
            "Epoch 7/20\n",
            "705/705 [==============================] - 58s 83ms/step - loss: 0.0110 - accuracy: 0.9009 - val_loss: 0.0160 - val_accuracy: 0.8645\n",
            "Epoch 8/20\n",
            "705/705 [==============================] - 58s 83ms/step - loss: 0.0101 - accuracy: 0.9083 - val_loss: 0.0170 - val_accuracy: 0.8554\n",
            "Epoch 9/20\n",
            "705/705 [==============================] - 58s 83ms/step - loss: 0.0093 - accuracy: 0.9146 - val_loss: 0.0170 - val_accuracy: 0.8630\n",
            "Epoch 10/20\n",
            "705/705 [==============================] - 59s 84ms/step - loss: 0.0085 - accuracy: 0.9214 - val_loss: 0.0180 - val_accuracy: 0.8611\n",
            "Epoch 11/20\n",
            "705/705 [==============================] - 59s 83ms/step - loss: 0.0076 - accuracy: 0.9330 - val_loss: 0.0183 - val_accuracy: 0.8598\n",
            "Epoch 12/20\n",
            "705/705 [==============================] - 59s 83ms/step - loss: 0.0069 - accuracy: 0.9386 - val_loss: 0.0195 - val_accuracy: 0.8585\n",
            "Epoch 13/20\n",
            "705/705 [==============================] - 58s 83ms/step - loss: 0.0061 - accuracy: 0.9464 - val_loss: 0.0206 - val_accuracy: 0.8606\n",
            "Epoch 14/20\n",
            "705/705 [==============================] - 58s 83ms/step - loss: 0.0057 - accuracy: 0.9494 - val_loss: 0.0218 - val_accuracy: 0.8592\n",
            "Epoch 15/20\n",
            "705/705 [==============================] - 58s 83ms/step - loss: 0.0052 - accuracy: 0.9550 - val_loss: 0.0238 - val_accuracy: 0.8581\n",
            "Epoch 16/20\n",
            "705/705 [==============================] - 58s 83ms/step - loss: 0.0047 - accuracy: 0.9584 - val_loss: 0.0255 - val_accuracy: 0.8518\n",
            "Epoch 17/20\n",
            "705/705 [==============================] - 58s 83ms/step - loss: 0.0043 - accuracy: 0.9632 - val_loss: 0.0262 - val_accuracy: 0.8588\n",
            "Epoch 18/20\n",
            "705/705 [==============================] - 59s 83ms/step - loss: 0.0040 - accuracy: 0.9668 - val_loss: 0.0289 - val_accuracy: 0.8517\n",
            "Epoch 19/20\n",
            "705/705 [==============================] - 58s 83ms/step - loss: 0.0037 - accuracy: 0.9692 - val_loss: 0.0296 - val_accuracy: 0.8541\n",
            "Epoch 20/20\n",
            "705/705 [==============================] - 59s 83ms/step - loss: 0.0033 - accuracy: 0.9723 - val_loss: 0.0315 - val_accuracy: 0.8529\n",
            "Epoch 1/20\n",
            "705/705 [==============================] - 71s 99ms/step - loss: 0.0796 - accuracy: 0.4495 - val_loss: 0.0216 - val_accuracy: 0.8111\n",
            "Epoch 2/20\n",
            "705/705 [==============================] - 69s 99ms/step - loss: 0.0191 - accuracy: 0.8341 - val_loss: 0.0180 - val_accuracy: 0.8445\n",
            "Epoch 3/20\n",
            "705/705 [==============================] - 69s 98ms/step - loss: 0.0155 - accuracy: 0.8629 - val_loss: 0.0164 - val_accuracy: 0.8562\n",
            "Epoch 4/20\n",
            "705/705 [==============================] - 70s 99ms/step - loss: 0.0135 - accuracy: 0.8794 - val_loss: 0.0160 - val_accuracy: 0.8613\n",
            "Epoch 5/20\n",
            "705/705 [==============================] - 69s 98ms/step - loss: 0.0120 - accuracy: 0.8907 - val_loss: 0.0155 - val_accuracy: 0.8638\n",
            "Epoch 6/20\n",
            "705/705 [==============================] - 69s 99ms/step - loss: 0.0107 - accuracy: 0.9027 - val_loss: 0.0160 - val_accuracy: 0.8616\n",
            "Epoch 7/20\n",
            "705/705 [==============================] - 69s 98ms/step - loss: 0.0096 - accuracy: 0.9135 - val_loss: 0.0163 - val_accuracy: 0.8626\n",
            "Epoch 8/20\n",
            "705/705 [==============================] - 70s 99ms/step - loss: 0.0085 - accuracy: 0.9226 - val_loss: 0.0169 - val_accuracy: 0.8630\n",
            "Epoch 9/20\n",
            "705/705 [==============================] - 70s 100ms/step - loss: 0.0076 - accuracy: 0.9294 - val_loss: 0.0182 - val_accuracy: 0.8598\n",
            "Epoch 10/20\n",
            "705/705 [==============================] - 69s 98ms/step - loss: 0.0066 - accuracy: 0.9390 - val_loss: 0.0191 - val_accuracy: 0.8637\n",
            "Epoch 11/20\n",
            "705/705 [==============================] - 70s 99ms/step - loss: 0.0059 - accuracy: 0.9462 - val_loss: 0.0210 - val_accuracy: 0.8611\n",
            "Epoch 12/20\n",
            "705/705 [==============================] - 69s 98ms/step - loss: 0.0051 - accuracy: 0.9539 - val_loss: 0.0219 - val_accuracy: 0.8585\n",
            "Epoch 13/20\n",
            "705/705 [==============================] - 70s 99ms/step - loss: 0.0046 - accuracy: 0.9586 - val_loss: 0.0238 - val_accuracy: 0.8589\n",
            "Epoch 14/20\n",
            "705/705 [==============================] - 70s 99ms/step - loss: 0.0041 - accuracy: 0.9640 - val_loss: 0.0261 - val_accuracy: 0.8543\n",
            "Epoch 15/20\n",
            "705/705 [==============================] - 70s 99ms/step - loss: 0.0038 - accuracy: 0.9682 - val_loss: 0.0279 - val_accuracy: 0.8551\n",
            "Epoch 16/20\n",
            "705/705 [==============================] - 69s 99ms/step - loss: 0.0034 - accuracy: 0.9705 - val_loss: 0.0296 - val_accuracy: 0.8521\n",
            "Epoch 17/20\n",
            "705/705 [==============================] - 70s 99ms/step - loss: 0.0032 - accuracy: 0.9732 - val_loss: 0.0317 - val_accuracy: 0.8529\n",
            "Epoch 18/20\n",
            "705/705 [==============================] - 70s 99ms/step - loss: 0.0028 - accuracy: 0.9774 - val_loss: 0.0326 - val_accuracy: 0.8547\n",
            "Epoch 19/20\n",
            "705/705 [==============================] - 70s 99ms/step - loss: 0.0027 - accuracy: 0.9791 - val_loss: 0.0333 - val_accuracy: 0.8546\n",
            "Epoch 20/20\n",
            "705/705 [==============================] - 70s 99ms/step - loss: 0.0024 - accuracy: 0.9810 - val_loss: 0.0361 - val_accuracy: 0.8550\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "szjUf_tFLPQl",
        "outputId": "32262cd9-46cf-40f6-cf3d-486b0e6ee78c"
      },
      "source": [
        "print(np.mean(train_result[0].history['accuracy']))\n",
        "print(np.mean(train_result[1].history['accuracy']))\n",
        "print(np.mean(train_result[2].history['accuracy']))\n",
        "print(np.mean(train_result[3].history['accuracy']))\n",
        "print(np.mean(train_result[4].history['accuracy']))\n",
        "print(np.mean(train_result[5].history['accuracy']))\n",
        "print(np.mean(train_result[6].history['accuracy']))\n",
        "print(np.mean(train_result[7].history['accuracy']))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8540619492530823\n",
            "0.8056826278567314\n",
            "0.8259430423378944\n",
            "0.8584718495607376\n",
            "0.8775099724531173\n",
            "0.8936181247234345\n",
            "0.9060123056173325\n",
            "0.9191982507705688\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "73S6BJWCLPQl"
      },
      "source": [
        "nets = 8\n",
        "model = [0] *nets\n",
        "\n",
        "for j in range(8):\n",
        "    model[j] = Sequential()\n",
        "    model[j].add(Conv2D(24,kernel_size=5,activation='relu',input_shape=(28,28,1)))\n",
        "    model[j].add(MaxPool2D())\n",
        "    model[j].add(Dropout(j*0.1))\n",
        "    model[j].add(Conv2D(48,kernel_size=5,activation='relu'))\n",
        "    model[j].add(MaxPool2D())\n",
        "    model[j].add(Dropout(j*0.1))\n",
        "    model[j].add(Flatten())\n",
        "    model[j].add(Dense(256, activation='relu'))\n",
        "    model[j].add(Dropout(j*0.1))\n",
        "    model[j].add(Dense(47, activation='sigmoid'))\n",
        "    model[j].compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MSY6M0siLPQl",
        "outputId": "ba037750-055d-44f9-e87d-c9fd4917f194"
      },
      "source": [
        "train_result = []\n",
        "for i in range (8):\n",
        "    train = model[i].fit(trainX, trainY,batch_size = 128, epochs = 20,\n",
        "                 validation_data=(validationX,validationY))\n",
        "    train_result.append(train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "705/705 [==============================] - 62s 88ms/step - loss: 0.0973 - accuracy: 0.3562 - val_loss: 0.0284 - val_accuracy: 0.7684\n",
            "Epoch 2/20\n",
            "705/705 [==============================] - 64s 90ms/step - loss: 0.0257 - accuracy: 0.7903 - val_loss: 0.0230 - val_accuracy: 0.8090\n",
            "Epoch 3/20\n",
            "705/705 [==============================] - 60s 85ms/step - loss: 0.0207 - accuracy: 0.8280 - val_loss: 0.0200 - val_accuracy: 0.8315\n",
            "Epoch 4/20\n",
            "705/705 [==============================] - 57s 81ms/step - loss: 0.0181 - accuracy: 0.8474 - val_loss: 0.0187 - val_accuracy: 0.8407\n",
            "Epoch 5/20\n",
            "705/705 [==============================] - 59s 83ms/step - loss: 0.0164 - accuracy: 0.8603 - val_loss: 0.0177 - val_accuracy: 0.8497\n",
            "Epoch 6/20\n",
            "705/705 [==============================] - 58s 82ms/step - loss: 0.0153 - accuracy: 0.8674 - val_loss: 0.0174 - val_accuracy: 0.8499\n",
            "Epoch 7/20\n",
            "705/705 [==============================] - 59s 83ms/step - loss: 0.0144 - accuracy: 0.8757 - val_loss: 0.0168 - val_accuracy: 0.8550\n",
            "Epoch 8/20\n",
            "705/705 [==============================] - 57s 81ms/step - loss: 0.0136 - accuracy: 0.8800 - val_loss: 0.0164 - val_accuracy: 0.8571\n",
            "Epoch 9/20\n",
            "705/705 [==============================] - 58s 82ms/step - loss: 0.0128 - accuracy: 0.8885 - val_loss: 0.0161 - val_accuracy: 0.8640 0.0128 - accuracy\n",
            "Epoch 10/20\n",
            "705/705 [==============================] - 57s 81ms/step - loss: 0.0123 - accuracy: 0.8928 - val_loss: 0.0163 - val_accuracy: 0.8616\n",
            "Epoch 11/20\n",
            "705/705 [==============================] - 57s 81ms/step - loss: 0.0117 - accuracy: 0.8961 - val_loss: 0.0164 - val_accuracy: 0.8618\n",
            "Epoch 12/20\n",
            "705/705 [==============================] - 57s 80ms/step - loss: 0.0113 - accuracy: 0.8997 - val_loss: 0.0162 - val_accuracy: 0.8639\n",
            "Epoch 13/20\n",
            "705/705 [==============================] - 58s 82ms/step - loss: 0.0106 - accuracy: 0.9059 - val_loss: 0.0175 - val_accuracy: 0.8563\n",
            "Epoch 14/20\n",
            "705/705 [==============================] - 57s 81ms/step - loss: 0.0101 - accuracy: 0.9107 - val_loss: 0.0170 - val_accuracy: 0.8593\n",
            "Epoch 15/20\n",
            "705/705 [==============================] - 57s 81ms/step - loss: 0.0097 - accuracy: 0.9152 - val_loss: 0.0173 - val_accuracy: 0.8629\n",
            "Epoch 16/20\n",
            "705/705 [==============================] - 56s 80ms/step - loss: 0.0092 - accuracy: 0.9191 - val_loss: 0.0177 - val_accuracy: 0.8565\n",
            "Epoch 17/20\n",
            "705/705 [==============================] - 59s 84ms/step - loss: 0.0089 - accuracy: 0.9220 - val_loss: 0.0182 - val_accuracy: 0.8613\n",
            "Epoch 18/20\n",
            "705/705 [==============================] - 58s 82ms/step - loss: 0.0086 - accuracy: 0.9253 - val_loss: 0.0185 - val_accuracy: 0.8566\n",
            "Epoch 19/20\n",
            "705/705 [==============================] - 54s 76ms/step - loss: 0.0081 - accuracy: 0.9297 - val_loss: 0.0192 - val_accuracy: 0.8575\n",
            "Epoch 20/20\n",
            "705/705 [==============================] - 54s 77ms/step - loss: 0.0078 - accuracy: 0.9326 - val_loss: 0.0198 - val_accuracy: 0.8574\n",
            "Epoch 1/20\n",
            "705/705 [==============================] - 58s 81ms/step - loss: 0.0995 - accuracy: 0.3230 - val_loss: 0.0253 - val_accuracy: 0.7871\n",
            "Epoch 2/20\n",
            "705/705 [==============================] - 60s 86ms/step - loss: 0.0256 - accuracy: 0.7862 - val_loss: 0.0202 - val_accuracy: 0.8272\n",
            "Epoch 3/20\n",
            "705/705 [==============================] - 58s 83ms/step - loss: 0.0207 - accuracy: 0.8223 - val_loss: 0.0180 - val_accuracy: 0.8413\n",
            "Epoch 4/20\n",
            "705/705 [==============================] - 58s 83ms/step - loss: 0.0181 - accuracy: 0.8453 - val_loss: 0.0169 - val_accuracy: 0.8486\n",
            "Epoch 5/20\n",
            "705/705 [==============================] - 58s 83ms/step - loss: 0.0170 - accuracy: 0.8521 - val_loss: 0.0162 - val_accuracy: 0.8552\n",
            "Epoch 6/20\n",
            "705/705 [==============================] - 59s 83ms/step - loss: 0.0159 - accuracy: 0.8603 - val_loss: 0.0158 - val_accuracy: 0.8572\n",
            "Epoch 7/20\n",
            "705/705 [==============================] - 59s 84ms/step - loss: 0.0151 - accuracy: 0.8672 - val_loss: 0.0159 - val_accuracy: 0.8563\n",
            "Epoch 8/20\n",
            "705/705 [==============================] - 59s 83ms/step - loss: 0.0144 - accuracy: 0.8717 - val_loss: 0.0155 - val_accuracy: 0.8602\n",
            "Epoch 9/20\n",
            "705/705 [==============================] - 58s 83ms/step - loss: 0.0140 - accuracy: 0.8740 - val_loss: 0.0153 - val_accuracy: 0.8643\n",
            "Epoch 10/20\n",
            "705/705 [==============================] - 59s 83ms/step - loss: 0.0133 - accuracy: 0.8831 - val_loss: 0.0151 - val_accuracy: 0.8663\n",
            "Epoch 11/20\n",
            "705/705 [==============================] - 58s 83ms/step - loss: 0.0130 - accuracy: 0.8843 - val_loss: 0.0152 - val_accuracy: 0.8662\n",
            "Epoch 12/20\n",
            "705/705 [==============================] - 59s 84ms/step - loss: 0.0125 - accuracy: 0.8881 - val_loss: 0.0152 - val_accuracy: 0.8664\n",
            "Epoch 13/20\n",
            "705/705 [==============================] - 59s 83ms/step - loss: 0.0120 - accuracy: 0.8929 - val_loss: 0.0150 - val_accuracy: 0.8657\n",
            "Epoch 14/20\n",
            "705/705 [==============================] - 59s 83ms/step - loss: 0.0120 - accuracy: 0.8912 - val_loss: 0.0153 - val_accuracy: 0.8678\n",
            "Epoch 15/20\n",
            "705/705 [==============================] - 58s 83ms/step - loss: 0.0114 - accuracy: 0.8972 - val_loss: 0.0152 - val_accuracy: 0.8663\n",
            "Epoch 16/20\n",
            "705/705 [==============================] - 57s 81ms/step - loss: 0.0113 - accuracy: 0.8991 - val_loss: 0.0153 - val_accuracy: 0.8668\n",
            "Epoch 17/20\n",
            "705/705 [==============================] - 57s 81ms/step - loss: 0.0110 - accuracy: 0.9021 - val_loss: 0.0154 - val_accuracy: 0.8661\n",
            "Epoch 18/20\n",
            "705/705 [==============================] - 57s 81ms/step - loss: 0.0107 - accuracy: 0.9045 - val_loss: 0.0155 - val_accuracy: 0.8670\n",
            "Epoch 19/20\n",
            "705/705 [==============================] - 57s 81ms/step - loss: 0.0105 - accuracy: 0.9065 - val_loss: 0.0157 - val_accuracy: 0.8660\n",
            "Epoch 20/20\n",
            "705/705 [==============================] - 57s 81ms/step - loss: 0.0103 - accuracy: 0.9084 - val_loss: 0.0157 - val_accuracy: 0.8664\n",
            "Epoch 1/20\n",
            "705/705 [==============================] - 59s 82ms/step - loss: 0.1078 - accuracy: 0.2667 - val_loss: 0.0257 - val_accuracy: 0.7857\n",
            "Epoch 2/20\n",
            "705/705 [==============================] - 58s 82ms/step - loss: 0.0283 - accuracy: 0.7656 - val_loss: 0.0202 - val_accuracy: 0.8276\n",
            "Epoch 3/20\n",
            "705/705 [==============================] - 58s 82ms/step - loss: 0.0225 - accuracy: 0.8093 - val_loss: 0.0181 - val_accuracy: 0.8414\n",
            "Epoch 4/20\n",
            "705/705 [==============================] - 58s 82ms/step - loss: 0.0200 - accuracy: 0.8284 - val_loss: 0.0169 - val_accuracy: 0.8481\n",
            "Epoch 5/20\n",
            "705/705 [==============================] - 58s 82ms/step - loss: 0.0186 - accuracy: 0.8378 - val_loss: 0.0163 - val_accuracy: 0.8534\n",
            "Epoch 6/20\n",
            "705/705 [==============================] - 58s 82ms/step - loss: 0.0176 - accuracy: 0.8469 - val_loss: 0.0157 - val_accuracy: 0.8575\n",
            "Epoch 7/20\n",
            "705/705 [==============================] - 58s 82ms/step - loss: 0.0171 - accuracy: 0.8502 - val_loss: 0.0156 - val_accuracy: 0.8592\n",
            "Epoch 8/20\n",
            "705/705 [==============================] - 58s 82ms/step - loss: 0.0163 - accuracy: 0.8584 - val_loss: 0.0152 - val_accuracy: 0.8614\n",
            "Epoch 9/20\n",
            "705/705 [==============================] - 58s 82ms/step - loss: 0.0159 - accuracy: 0.8580 - val_loss: 0.0149 - val_accuracy: 0.8654\n",
            "Epoch 10/20\n",
            "705/705 [==============================] - 58s 82ms/step - loss: 0.0153 - accuracy: 0.8633 - val_loss: 0.0148 - val_accuracy: 0.8674\n",
            "Epoch 11/20\n",
            "705/705 [==============================] - 59s 83ms/step - loss: 0.0150 - accuracy: 0.8657 - val_loss: 0.0149 - val_accuracy: 0.8649\n",
            "Epoch 12/20\n",
            "705/705 [==============================] - 58s 82ms/step - loss: 0.0144 - accuracy: 0.8712 - val_loss: 0.0146 - val_accuracy: 0.8684\n",
            "Epoch 13/20\n",
            "705/705 [==============================] - 58s 82ms/step - loss: 0.0143 - accuracy: 0.8740 - val_loss: 0.0147 - val_accuracy: 0.8688\n",
            "Epoch 14/20\n",
            "705/705 [==============================] - 58s 82ms/step - loss: 0.0139 - accuracy: 0.8755 - val_loss: 0.0147 - val_accuracy: 0.8672\n",
            "Epoch 15/20\n",
            "705/705 [==============================] - 58s 82ms/step - loss: 0.0138 - accuracy: 0.8778 - val_loss: 0.0146 - val_accuracy: 0.8680\n",
            "Epoch 16/20\n",
            "705/705 [==============================] - 58s 82ms/step - loss: 0.0135 - accuracy: 0.8784 - val_loss: 0.0147 - val_accuracy: 0.8679\n",
            "Epoch 17/20\n",
            "705/705 [==============================] - 56s 79ms/step - loss: 0.0132 - accuracy: 0.8830 - val_loss: 0.0145 - val_accuracy: 0.8685\n",
            "Epoch 18/20\n",
            "705/705 [==============================] - 56s 79ms/step - loss: 0.0130 - accuracy: 0.8863 - val_loss: 0.0146 - val_accuracy: 0.8691\n",
            "Epoch 19/20\n",
            "705/705 [==============================] - 56s 80ms/step - loss: 0.0129 - accuracy: 0.8818 - val_loss: 0.0145 - val_accuracy: 0.8719\n",
            "Epoch 20/20\n",
            "705/705 [==============================] - 56s 79ms/step - loss: 0.0128 - accuracy: 0.8863 - val_loss: 0.0146 - val_accuracy: 0.8690\n",
            "Epoch 1/20\n",
            "705/705 [==============================] - 57s 80ms/step - loss: 0.1071 - accuracy: 0.2467 - val_loss: 0.0268 - val_accuracy: 0.7776\n",
            "Epoch 2/20\n",
            "705/705 [==============================] - 56s 79ms/step - loss: 0.0317 - accuracy: 0.7342 - val_loss: 0.0207 - val_accuracy: 0.8177\n",
            "Epoch 3/20\n",
            "705/705 [==============================] - 56s 79ms/step - loss: 0.0252 - accuracy: 0.7862 - val_loss: 0.0185 - val_accuracy: 0.8346\n",
            "Epoch 4/20\n",
            "705/705 [==============================] - 59s 83ms/step - loss: 0.0223 - accuracy: 0.8107 - val_loss: 0.0176 - val_accuracy: 0.8432\n",
            "Epoch 5/20\n",
            "705/705 [==============================] - 56s 80ms/step - loss: 0.0211 - accuracy: 0.8190 - val_loss: 0.0168 - val_accuracy: 0.8481\n",
            "Epoch 6/20\n",
            "705/705 [==============================] - 56s 79ms/step - loss: 0.0201 - accuracy: 0.8254 - val_loss: 0.0163 - val_accuracy: 0.8502\n",
            "Epoch 7/20\n",
            "705/705 [==============================] - 56s 79ms/step - loss: 0.0192 - accuracy: 0.8315 - val_loss: 0.0158 - val_accuracy: 0.8575\n",
            "Epoch 8/20\n",
            "705/705 [==============================] - 56s 79ms/step - loss: 0.0185 - accuracy: 0.8390 - val_loss: 0.0155 - val_accuracy: 0.8581\n",
            "Epoch 9/20\n",
            "705/705 [==============================] - 56s 79ms/step - loss: 0.0180 - accuracy: 0.8434 - val_loss: 0.0154 - val_accuracy: 0.8570\n",
            "Epoch 10/20\n",
            "705/705 [==============================] - 56s 79ms/step - loss: 0.0176 - accuracy: 0.8446 - val_loss: 0.0153 - val_accuracy: 0.8590\n",
            "Epoch 11/20\n",
            "705/705 [==============================] - 56s 79ms/step - loss: 0.0175 - accuracy: 0.8470 - val_loss: 0.0151 - val_accuracy: 0.8629\n",
            "Epoch 12/20\n",
            "705/705 [==============================] - 56s 79ms/step - loss: 0.0171 - accuracy: 0.8500 - val_loss: 0.0149 - val_accuracy: 0.8623\n",
            "Epoch 13/20\n",
            "705/705 [==============================] - 56s 79ms/step - loss: 0.0167 - accuracy: 0.8536 - val_loss: 0.0148 - val_accuracy: 0.8636\n",
            "Epoch 14/20\n",
            "705/705 [==============================] - 56s 79ms/step - loss: 0.0166 - accuracy: 0.8530 - val_loss: 0.0146 - val_accuracy: 0.8665\n",
            "Epoch 15/20\n",
            "705/705 [==============================] - 56s 79ms/step - loss: 0.0162 - accuracy: 0.8561 - val_loss: 0.0144 - val_accuracy: 0.8679\n",
            "Epoch 16/20\n",
            "705/705 [==============================] - 56s 79ms/step - loss: 0.0159 - accuracy: 0.8614 - val_loss: 0.0144 - val_accuracy: 0.8659\n",
            "Epoch 17/20\n",
            "705/705 [==============================] - 56s 79ms/step - loss: 0.0158 - accuracy: 0.8583 - val_loss: 0.0145 - val_accuracy: 0.8674\n",
            "Epoch 18/20\n",
            "705/705 [==============================] - 56s 79ms/step - loss: 0.0156 - accuracy: 0.8628 - val_loss: 0.0144 - val_accuracy: 0.8672\n",
            "Epoch 19/20\n",
            "705/705 [==============================] - 56s 79ms/step - loss: 0.0152 - accuracy: 0.8642 - val_loss: 0.0144 - val_accuracy: 0.8690\n",
            "Epoch 20/20\n",
            "705/705 [==============================] - 56s 79ms/step - loss: 0.0154 - accuracy: 0.8643 - val_loss: 0.0144 - val_accuracy: 0.8678\n",
            "Epoch 1/20\n",
            "705/705 [==============================] - 58s 81ms/step - loss: 0.1154 - accuracy: 0.2071 - val_loss: 0.0289 - val_accuracy: 0.7635\n",
            "Epoch 2/20\n",
            "705/705 [==============================] - 57s 81ms/step - loss: 0.0349 - accuracy: 0.7091 - val_loss: 0.0219 - val_accuracy: 0.8094\n",
            "Epoch 3/20\n",
            "705/705 [==============================] - 57s 81ms/step - loss: 0.0282 - accuracy: 0.7651 - val_loss: 0.0194 - val_accuracy: 0.8299\n",
            "Epoch 4/20\n",
            "705/705 [==============================] - 57s 81ms/step - loss: 0.0253 - accuracy: 0.7841 - val_loss: 0.0183 - val_accuracy: 0.8359\n",
            "Epoch 5/20\n",
            "705/705 [==============================] - 56s 80ms/step - loss: 0.0234 - accuracy: 0.8005 - val_loss: 0.0176 - val_accuracy: 0.8426\n",
            "Epoch 6/20\n",
            "705/705 [==============================] - 57s 80ms/step - loss: 0.0222 - accuracy: 0.8099 - val_loss: 0.0167 - val_accuracy: 0.8501\n",
            "Epoch 7/20\n",
            "705/705 [==============================] - 56s 80ms/step - loss: 0.0215 - accuracy: 0.8155 - val_loss: 0.0166 - val_accuracy: 0.8502\n",
            "Epoch 8/20\n",
            "705/705 [==============================] - 56s 80ms/step - loss: 0.0209 - accuracy: 0.8199 - val_loss: 0.0160 - val_accuracy: 0.8551\n",
            "Epoch 9/20\n",
            "705/705 [==============================] - 57s 81ms/step - loss: 0.0204 - accuracy: 0.8225 - val_loss: 0.0158 - val_accuracy: 0.8546\n",
            "Epoch 10/20\n",
            "705/705 [==============================] - 57s 80ms/step - loss: 0.0199 - accuracy: 0.8272 - val_loss: 0.0157 - val_accuracy: 0.8559\n",
            "Epoch 11/20\n",
            "705/705 [==============================] - 57s 81ms/step - loss: 0.0197 - accuracy: 0.8297 - val_loss: 0.0154 - val_accuracy: 0.8582\n",
            "Epoch 12/20\n",
            "705/705 [==============================] - 57s 81ms/step - loss: 0.0196 - accuracy: 0.8288 - val_loss: 0.0153 - val_accuracy: 0.8582\n",
            "Epoch 13/20\n",
            "705/705 [==============================] - 57s 81ms/step - loss: 0.0191 - accuracy: 0.8336 - val_loss: 0.0152 - val_accuracy: 0.8604\n",
            "Epoch 14/20\n",
            "705/705 [==============================] - 57s 81ms/step - loss: 0.0189 - accuracy: 0.8361 - val_loss: 0.0151 - val_accuracy: 0.8623\n",
            "Epoch 15/20\n",
            "705/705 [==============================] - 57s 81ms/step - loss: 0.0188 - accuracy: 0.8354 - val_loss: 0.0149 - val_accuracy: 0.8638\n",
            "Epoch 16/20\n",
            "705/705 [==============================] - 57s 81ms/step - loss: 0.0185 - accuracy: 0.8385 - val_loss: 0.0149 - val_accuracy: 0.8628\n",
            "Epoch 17/20\n",
            "705/705 [==============================] - 57s 81ms/step - loss: 0.0182 - accuracy: 0.8407 - val_loss: 0.0149 - val_accuracy: 0.8629\n",
            "Epoch 18/20\n",
            "705/705 [==============================] - 57s 81ms/step - loss: 0.0180 - accuracy: 0.8405 - val_loss: 0.0148 - val_accuracy: 0.8651\n",
            "Epoch 19/20\n",
            "705/705 [==============================] - 57s 81ms/step - loss: 0.0182 - accuracy: 0.8415 - val_loss: 0.0148 - val_accuracy: 0.8652\n",
            "Epoch 20/20\n",
            "705/705 [==============================] - 57s 80ms/step - loss: 0.0179 - accuracy: 0.8426 - val_loss: 0.0148 - val_accuracy: 0.8629\n",
            "Epoch 1/20\n",
            "705/705 [==============================] - 58s 81ms/step - loss: 0.1256 - accuracy: 0.1545 - val_loss: 0.0340 - val_accuracy: 0.7387\n",
            "Epoch 2/20\n",
            "705/705 [==============================] - 57s 81ms/step - loss: 0.0417 - accuracy: 0.6451 - val_loss: 0.0253 - val_accuracy: 0.7907\n",
            "Epoch 3/20\n",
            "705/705 [==============================] - 57s 81ms/step - loss: 0.0333 - accuracy: 0.7194 - val_loss: 0.0219 - val_accuracy: 0.8099\n",
            "Epoch 4/20\n",
            "705/705 [==============================] - 57s 81ms/step - loss: 0.0297 - accuracy: 0.7513 - val_loss: 0.0201 - val_accuracy: 0.8223\n",
            "Epoch 5/20\n",
            "705/705 [==============================] - 57s 81ms/step - loss: 0.0280 - accuracy: 0.7615 - val_loss: 0.0189 - val_accuracy: 0.8280\n",
            "Epoch 6/20\n",
            "705/705 [==============================] - 57s 81ms/step - loss: 0.0263 - accuracy: 0.7755 - val_loss: 0.0182 - val_accuracy: 0.8367\n",
            "Epoch 7/20\n",
            "705/705 [==============================] - 57s 81ms/step - loss: 0.0253 - accuracy: 0.7848 - val_loss: 0.0177 - val_accuracy: 0.8402\n",
            "Epoch 8/20\n",
            "705/705 [==============================] - 57s 81ms/step - loss: 0.0248 - accuracy: 0.7864 - val_loss: 0.0174 - val_accuracy: 0.8417\n",
            "Epoch 9/20\n",
            "705/705 [==============================] - 57s 82ms/step - loss: 0.0240 - accuracy: 0.7929 - val_loss: 0.0171 - val_accuracy: 0.8424\n",
            "Epoch 10/20\n",
            "705/705 [==============================] - 57s 81ms/step - loss: 0.0238 - accuracy: 0.7967 - val_loss: 0.0168 - val_accuracy: 0.8461\n",
            "Epoch 11/20\n",
            "705/705 [==============================] - 57s 81ms/step - loss: 0.0232 - accuracy: 0.8012 - val_loss: 0.0166 - val_accuracy: 0.8480\n",
            "Epoch 12/20\n",
            "705/705 [==============================] - 57s 81ms/step - loss: 0.0232 - accuracy: 0.7993 - val_loss: 0.0165 - val_accuracy: 0.8483\n",
            "Epoch 13/20\n",
            "705/705 [==============================] - 57s 81ms/step - loss: 0.0227 - accuracy: 0.8041 - val_loss: 0.0163 - val_accuracy: 0.8517\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 14/20\n",
            "705/705 [==============================] - 56s 79ms/step - loss: 0.0224 - accuracy: 0.8070 - val_loss: 0.0161 - val_accuracy: 0.8508\n",
            "Epoch 15/20\n",
            "705/705 [==============================] - 56s 79ms/step - loss: 0.0221 - accuracy: 0.8074 - val_loss: 0.0159 - val_accuracy: 0.8534\n",
            "Epoch 16/20\n",
            "705/705 [==============================] - 56s 79ms/step - loss: 0.0219 - accuracy: 0.8115 - val_loss: 0.0159 - val_accuracy: 0.8531\n",
            "Epoch 17/20\n",
            "705/705 [==============================] - 56s 79ms/step - loss: 0.0216 - accuracy: 0.8165 - val_loss: 0.0159 - val_accuracy: 0.8517\n",
            "Epoch 18/20\n",
            "705/705 [==============================] - 56s 79ms/step - loss: 0.0217 - accuracy: 0.8115 - val_loss: 0.0158 - val_accuracy: 0.8531\n",
            "Epoch 19/20\n",
            "705/705 [==============================] - 57s 80ms/step - loss: 0.0213 - accuracy: 0.8157 - val_loss: 0.0157 - val_accuracy: 0.8557\n",
            "Epoch 20/20\n",
            "705/705 [==============================] - 57s 81ms/step - loss: 0.0213 - accuracy: 0.8145 - val_loss: 0.0156 - val_accuracy: 0.8559\n",
            "Epoch 1/20\n",
            "705/705 [==============================] - 58s 81ms/step - loss: 0.1287 - accuracy: 0.1244 - val_loss: 0.0405 - val_accuracy: 0.7090\n",
            "Epoch 2/20\n",
            "705/705 [==============================] - 57s 81ms/step - loss: 0.0489 - accuracy: 0.5745 - val_loss: 0.0280 - val_accuracy: 0.7742\n",
            "Epoch 3/20\n",
            "705/705 [==============================] - 58s 82ms/step - loss: 0.0393 - accuracy: 0.6652 - val_loss: 0.0250 - val_accuracy: 0.8005\n",
            "Epoch 4/20\n",
            "705/705 [==============================] - 57s 81ms/step - loss: 0.0352 - accuracy: 0.7041 - val_loss: 0.0224 - val_accuracy: 0.8087\n",
            "Epoch 5/20\n",
            "705/705 [==============================] - 58s 82ms/step - loss: 0.0331 - accuracy: 0.7200 - val_loss: 0.0214 - val_accuracy: 0.8172\n",
            "Epoch 6/20\n",
            "705/705 [==============================] - 57s 81ms/step - loss: 0.0316 - accuracy: 0.7330 - val_loss: 0.0205 - val_accuracy: 0.8214\n",
            "Epoch 7/20\n",
            "705/705 [==============================] - 58s 82ms/step - loss: 0.0305 - accuracy: 0.7396 - val_loss: 0.0197 - val_accuracy: 0.8260\n",
            "Epoch 8/20\n",
            "705/705 [==============================] - 60s 85ms/step - loss: 0.0295 - accuracy: 0.7509 - val_loss: 0.0195 - val_accuracy: 0.8300\n",
            "Epoch 9/20\n",
            "705/705 [==============================] - 56s 80ms/step - loss: 0.0291 - accuracy: 0.7513 - val_loss: 0.0189 - val_accuracy: 0.8310\n",
            "Epoch 10/20\n",
            "705/705 [==============================] - 56s 79ms/step - loss: 0.0286 - accuracy: 0.7572 - val_loss: 0.0189 - val_accuracy: 0.8320\n",
            "Epoch 11/20\n",
            "705/705 [==============================] - 56s 80ms/step - loss: 0.0281 - accuracy: 0.7625 - val_loss: 0.0185 - val_accuracy: 0.8347\n",
            "Epoch 12/20\n",
            "705/705 [==============================] - 56s 80ms/step - loss: 0.0279 - accuracy: 0.7653 - val_loss: 0.0181 - val_accuracy: 0.8352\n",
            "Epoch 13/20\n",
            "705/705 [==============================] - 56s 80ms/step - loss: 0.0275 - accuracy: 0.7649 - val_loss: 0.0180 - val_accuracy: 0.8391\n",
            "Epoch 14/20\n",
            "705/705 [==============================] - 56s 79ms/step - loss: 0.0273 - accuracy: 0.7665 - val_loss: 0.0177 - val_accuracy: 0.8396\n",
            "Epoch 15/20\n",
            "705/705 [==============================] - 56s 80ms/step - loss: 0.0269 - accuracy: 0.7711 - val_loss: 0.0177 - val_accuracy: 0.8376\n",
            "Epoch 16/20\n",
            "705/705 [==============================] - 56s 79ms/step - loss: 0.0268 - accuracy: 0.7718 - val_loss: 0.0176 - val_accuracy: 0.8416\n",
            "Epoch 17/20\n",
            "705/705 [==============================] - 56s 80ms/step - loss: 0.0266 - accuracy: 0.7718 - val_loss: 0.0175 - val_accuracy: 0.8427\n",
            "Epoch 18/20\n",
            "705/705 [==============================] - 56s 79ms/step - loss: 0.0263 - accuracy: 0.7748 - val_loss: 0.0175 - val_accuracy: 0.8422\n",
            "Epoch 19/20\n",
            "705/705 [==============================] - 56s 80ms/step - loss: 0.0265 - accuracy: 0.7748 - val_loss: 0.0172 - val_accuracy: 0.8451\n",
            "Epoch 20/20\n",
            "705/705 [==============================] - 56s 80ms/step - loss: 0.0262 - accuracy: 0.7733 - val_loss: 0.0172 - val_accuracy: 0.8446\n",
            "Epoch 1/20\n",
            "705/705 [==============================] - 57s 80ms/step - loss: 0.1476 - accuracy: 0.0555 - val_loss: 0.0577 - val_accuracy: 0.6387\n",
            "Epoch 2/20\n",
            "705/705 [==============================] - 57s 80ms/step - loss: 0.0620 - accuracy: 0.4458 - val_loss: 0.0349 - val_accuracy: 0.7388\n",
            "Epoch 3/20\n",
            "705/705 [==============================] - 56s 80ms/step - loss: 0.0489 - accuracy: 0.5772 - val_loss: 0.0298 - val_accuracy: 0.7701\n",
            "Epoch 4/20\n",
            "705/705 [==============================] - 56s 80ms/step - loss: 0.0439 - accuracy: 0.6222 - val_loss: 0.0274 - val_accuracy: 0.7838\n",
            "Epoch 5/20\n",
            "705/705 [==============================] - 56s 80ms/step - loss: 0.0414 - accuracy: 0.6434 - val_loss: 0.0255 - val_accuracy: 0.7916\n",
            "Epoch 6/20\n",
            "705/705 [==============================] - 56s 80ms/step - loss: 0.0396 - accuracy: 0.6626 - val_loss: 0.0243 - val_accuracy: 0.8003\n",
            "Epoch 7/20\n",
            "705/705 [==============================] - 56s 80ms/step - loss: 0.0383 - accuracy: 0.6703 - val_loss: 0.0237 - val_accuracy: 0.8026\n",
            "Epoch 8/20\n",
            "705/705 [==============================] - 56s 80ms/step - loss: 0.0375 - accuracy: 0.6791 - val_loss: 0.0231 - val_accuracy: 0.8056\n",
            "Epoch 9/20\n",
            "705/705 [==============================] - 56s 80ms/step - loss: 0.0369 - accuracy: 0.6844 - val_loss: 0.0223 - val_accuracy: 0.8110\n",
            "Epoch 10/20\n",
            "705/705 [==============================] - 56s 80ms/step - loss: 0.0365 - accuracy: 0.6887 - val_loss: 0.0221 - val_accuracy: 0.8120\n",
            "Epoch 11/20\n",
            "705/705 [==============================] - 56s 80ms/step - loss: 0.0359 - accuracy: 0.6893 - val_loss: 0.0219 - val_accuracy: 0.8140\n",
            "Epoch 12/20\n",
            "705/705 [==============================] - 57s 80ms/step - loss: 0.0357 - accuracy: 0.6929 - val_loss: 0.0216 - val_accuracy: 0.8135\n",
            "Epoch 13/20\n",
            "705/705 [==============================] - 56s 80ms/step - loss: 0.0352 - accuracy: 0.7007 - val_loss: 0.0216 - val_accuracy: 0.8185\n",
            "Epoch 14/20\n",
            "705/705 [==============================] - 56s 80ms/step - loss: 0.0352 - accuracy: 0.7006 - val_loss: 0.0212 - val_accuracy: 0.8191\n",
            "Epoch 15/20\n",
            "705/705 [==============================] - 56s 80ms/step - loss: 0.0345 - accuracy: 0.7034 - val_loss: 0.0213 - val_accuracy: 0.8176\n",
            "Epoch 16/20\n",
            "705/705 [==============================] - 56s 80ms/step - loss: 0.0346 - accuracy: 0.7062 - val_loss: 0.0212 - val_accuracy: 0.8189\n",
            "Epoch 17/20\n",
            "705/705 [==============================] - 56s 80ms/step - loss: 0.0345 - accuracy: 0.7035 - val_loss: 0.0209 - val_accuracy: 0.8193\n",
            "Epoch 18/20\n",
            "705/705 [==============================] - 57s 80ms/step - loss: 0.0342 - accuracy: 0.7065 - val_loss: 0.0209 - val_accuracy: 0.8207\n",
            "Epoch 19/20\n",
            "705/705 [==============================] - 57s 80ms/step - loss: 0.0340 - accuracy: 0.7105 - val_loss: 0.0207 - val_accuracy: 0.8226\n",
            "Epoch 20/20\n",
            "705/705 [==============================] - 57s 80ms/step - loss: 0.0337 - accuracy: 0.7111 - val_loss: 0.0205 - val_accuracy: 0.8225\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xV2CA9_8LPQm",
        "outputId": "16d33d03-42fc-4d3d-aa95-9c5dd6630024"
      },
      "source": [
        "print(np.mean(train_result[0].history['accuracy']))\n",
        "print(np.mean(train_result[1].history['accuracy']))\n",
        "print(np.mean(train_result[2].history['accuracy']))\n",
        "print(np.mean(train_result[3].history['accuracy']))\n",
        "print(np.mean(train_result[4].history['accuracy']))\n",
        "print(np.mean(train_result[5].history['accuracy']))\n",
        "print(np.mean(train_result[6].history['accuracy']))\n",
        "print(np.mean(train_result[7].history['accuracy']))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8724080234766006\n",
            "0.8580241590738297\n",
            "0.8398376524448394\n",
            "0.8191544756293296\n",
            "0.7976706564426422\n",
            "0.7642957642674446\n",
            "0.7214184373617172\n",
            "0.645595633238554\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GpAqk9DpLPQm"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(24,kernel_size=5,activation='relu',input_shape=(28,28,1)))\n",
        "model.add(MaxPool2D())\n",
        "model.add(Dropout(0))\n",
        "model.add(Conv2D(48,kernel_size=5,activation='relu'))\n",
        "model.add(MaxPool2D())\n",
        "model.add(Dropout(0))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dropout(0))\n",
        "model.add(Dense(47, activation='sigmoid'))\n",
        "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qjV5gUHJLPQm",
        "outputId": "6c20ece8-1a6f-4269-9c43-af54e7faea04"
      },
      "source": [
        "train = model.fit(trainX[:10], trainY[:10],batch_size = 128, epochs = 20,validation_data=(validationX[:10],validationY[:10]))\n",
        "#train.history['accuracy']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "1/1 [==============================] - 1s 887ms/step - loss: 0.6930 - accuracy: 0.0000e+00 - val_loss: 0.6272 - val_accuracy: 0.1000\n",
            "Epoch 2/20\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 0.6272 - accuracy: 0.0000e+00 - val_loss: 0.5552 - val_accuracy: 0.1000\n",
            "Epoch 3/20\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 0.5551 - accuracy: 0.0000e+00 - val_loss: 0.4623 - val_accuracy: 0.1000\n",
            "Epoch 4/20\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 0.4624 - accuracy: 0.1000 - val_loss: 0.3520 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/20\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 0.3527 - accuracy: 0.1000 - val_loss: 0.2450 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/20\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.2441 - accuracy: 0.1000 - val_loss: 0.1647 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/20\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.1594 - accuracy: 0.1000 - val_loss: 0.1222 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/20\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 0.1093 - accuracy: 0.0000e+00 - val_loss: 0.1168 - val_accuracy: 0.1000\n",
            "Epoch 9/20\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 0.0917 - accuracy: 0.0000e+00 - val_loss: 0.1353 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/20\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 0.0923 - accuracy: 0.2000 - val_loss: 0.1619 - val_accuracy: 0.0000e+00\n",
            "Epoch 11/20\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 0.0951 - accuracy: 0.2000 - val_loss: 0.1903 - val_accuracy: 0.0000e+00\n",
            "Epoch 12/20\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 0.0950 - accuracy: 0.2000 - val_loss: 0.2169 - val_accuracy: 0.0000e+00\n",
            "Epoch 13/20\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 0.0915 - accuracy: 0.2000 - val_loss: 0.2330 - val_accuracy: 0.0000e+00\n",
            "Epoch 14/20\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 0.0804 - accuracy: 0.2000 - val_loss: 0.2460 - val_accuracy: 0.0000e+00\n",
            "Epoch 15/20\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 0.0680 - accuracy: 0.3000 - val_loss: 0.2644 - val_accuracy: 0.0000e+00\n",
            "Epoch 16/20\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 0.0624 - accuracy: 0.6000 - val_loss: 0.2872 - val_accuracy: 0.0000e+00\n",
            "Epoch 17/20\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 0.0645 - accuracy: 0.5000 - val_loss: 0.3020 - val_accuracy: 0.1000\n",
            "Epoch 18/20\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 0.0636 - accuracy: 0.5000 - val_loss: 0.3070 - val_accuracy: 0.0000e+00\n",
            "Epoch 19/20\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 0.0551 - accuracy: 0.4000 - val_loss: 0.3132 - val_accuracy: 0.0000e+00\n",
            "Epoch 20/20\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 0.0484 - accuracy: 0.5000 - val_loss: 0.3245 - val_accuracy: 0.0000e+00\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_teQ8f2oLPQm",
        "outputId": "90062640-77c1-46b0-d178-cd1529df5dcd"
      },
      "source": [
        "train.history['accuracy']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.5516068339347839,\n",
              " 0.799589991569519,\n",
              " 0.8289893865585327,\n",
              " 0.8463098406791687,\n",
              " 0.8576130270957947,\n",
              " 0.864749550819397,\n",
              " 0.8726839423179626,\n",
              " 0.8789893388748169,\n",
              " 0.8841201066970825,\n",
              " 0.890159547328949,\n",
              " 0.8947252035140991,\n",
              " 0.8987699747085571,\n",
              " 0.9041888117790222,\n",
              " 0.9085327982902527,\n",
              " 0.9118240475654602,\n",
              " 0.9162898659706116,\n",
              " 0.9219193458557129,\n",
              " 0.9248892068862915,\n",
              " 0.9282247424125671,\n",
              " 0.9312499761581421]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WV5m6W83LPQn",
        "outputId": "f87d4b50-747a-4fb9-e361-cbca57667b29"
      },
      "source": [
        "model.evaluate(trainX, trainY, batch_size=128)\n",
        "model.evaluate(validationX,validationY,batch_size=128)\n",
        "model.evaluate(testX,testY,batch_size=128)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "705/705 [==============================] - 14s 19ms/step - loss: 0.0071 - accuracy: 0.9390\n",
            "177/177 [==============================] - 3s 19ms/step - loss: 0.0195 - accuracy: 0.8615\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.0207 - accuracy: 0.8592\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.02065831981599331, 0.8592021465301514]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sbFj9ANbLPQn",
        "outputId": "907ae1a1-9f14-453a-9255-e5d72226ee66"
      },
      "source": [
        "model.predict_classes(trainX[:10])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 6, 13, 18,  1, 20,  6,  6,  1,  6,  6], dtype=int64)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "10bzOR1TLPQo"
      },
      "source": [
        "images_train, trainY = extract_training_samples('balanced')\n",
        "images_test, testY = extract_test_samples('balanced')\n",
        "#reshape data\n",
        "trainX =images_train.reshape(images_train.shape[0],28,28,1)\n",
        "testX = images_test.reshape(images_test.shape[0],28,28,1)\n",
        "#normalization \n",
        "trainX = tf.keras.utils.normalize(trainX, axis=-1, order=2)\n",
        "testX = tf.keras.utils.normalize(testX, axis=-1, order=2)\n",
        "#train validation split \n",
        "trainX, validationX, trainY, validationY = train_test_split(trainX,trainY,test_size = 0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wVt7BpFrLPQo",
        "outputId": "2da30865-a0ff-43f9-ebef-ea4f2a6e6c86"
      },
      "source": [
        "#confusion matrix \n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "x = confusion_matrix(trainY,model.predict_classes(trainX))\n",
        "x.shape\n",
        "#dendrogram \n",
        "from scipy.cluster import hierarchy\n",
        "plt.figure(figsize=(10, 7))\n",
        "Y = hierarchy.distance.pdist(x, metric='euclidean')\n",
        "Z = hierarchy.linkage(Y, method='complete')\n",
        "ax = hierarchy.dendrogram(Z, show_contracted=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vNLPIjHYLPQo",
        "outputId": "115dfb08-651e-4dd2-9389-e796168e5e12"
      },
      "source": [
        "x = confusion_matrix(validationY,model.predict_classes(validationX))\n",
        "x.shape\n",
        "#dendrogram \n",
        "from scipy.cluster import hierarchy\n",
        "plt.figure(figsize=(10, 7))\n",
        "Y = hierarchy.distance.pdist(x, metric='euclidean')\n",
        "Z = hierarchy.linkage(Y, method='complete')\n",
        "ax = hierarchy.dendrogram(Z, show_contracted=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8dYbuzS8LPQp",
        "outputId": "cc2ac741-13ac-4340-ed38-058c1ce51572"
      },
      "source": [
        "x = confusion_matrix(testY,model.predict_classes(testX))\n",
        "x.shape\n",
        "#dendrogram \n",
        "from scipy.cluster import hierarchy\n",
        "plt.figure(figsize=(10, 7))\n",
        "Y = hierarchy.distance.pdist(x, metric='euclidean')\n",
        "Z = hierarchy.linkage(Y, method='complete')\n",
        "ax = hierarchy.dendrogram(Z, show_contracted=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n_G7cu6sLPQp"
      },
      "source": [
        "#convolution autoencoder \n",
        "from keras.layers import Dense, Flatten, Reshape, Input, InputLayer\n",
        "from keras.models import Sequential, Model\n",
        "images_train, trainY = extract_training_samples('balanced')\n",
        "images_test, testY = extract_test_samples('balanced')\n",
        "#reshape data\n",
        "trainX =images_train.reshape(images_train.shape[0],28,28,1)\n",
        "testX = images_test.reshape(images_test.shape[0],28,28,1)\n",
        "#normalization \n",
        "trainX = tf.keras.utils.normalize(trainX, axis=-1, order=2)\n",
        "testX = tf.keras.utils.normalize(testX, axis=-1, order=2)\n",
        "#train validation split \n",
        "trainX, validationX, trainY, validationY = train_test_split(trainX,trainY,test_size = 0.2)\n",
        "#to_caegorical \n",
        "#trainY = to_categorical (trainY)\n",
        "#validationY = to_categorical(validationY)\n",
        "#testY = to_categorical(testY)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y5jtus1VLPQp",
        "outputId": "e9df4ac5-680a-40b4-9042-3c09a8492101"
      },
      "source": [
        "encoding_dim = 28\n",
        "input_img = keras.Input(shape=(28, 28, 1))\n",
        "\n",
        "x = layers.Conv2D(16, (3, 3), activation='relu', padding='same')(input_img)\n",
        "x = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
        "x = layers.Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
        "x = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
        "x = layers.Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
        "encoded = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
        "\n",
        "# at this point the representation is (4, 4, 8) i.e. 128-dimensional\n",
        "\n",
        "x = layers.Conv2D(8, (3, 3), activation='relu', padding='same')(encoded)\n",
        "x = layers.UpSampling2D((2, 2))(x)\n",
        "x = layers.Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
        "x = layers.UpSampling2D((2, 2))(x)\n",
        "x = layers.Conv2D(16, (3, 3), activation='relu')(x)\n",
        "x = layers.UpSampling2D((2, 2))(x)\n",
        "decoded = layers.Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
        "\n",
        "autoencoder = keras.Model(input_img, decoded)\n",
        "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
        "autoencoder_train = autoencoder.fit(trainX, trainX,\n",
        "                epochs=20,\n",
        "                batch_size=128,\n",
        "                shuffle=True,\n",
        "                validation_data=(validationX, validationX))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "705/705 [==============================] - 109s 152ms/step - loss: 0.2945 - val_loss: 0.1334\n",
            "Epoch 2/20\n",
            "705/705 [==============================] - 104s 148ms/step - loss: 0.1268 - val_loss: 0.1109\n",
            "Epoch 3/20\n",
            "705/705 [==============================] - 111s 157ms/step - loss: 0.1088 - val_loss: 0.1017\n",
            "Epoch 4/20\n",
            "705/705 [==============================] - 103s 146ms/step - loss: 0.1008 - val_loss: 0.0958\n",
            "Epoch 5/20\n",
            "705/705 [==============================] - 103s 146ms/step - loss: 0.0952 - val_loss: 0.0917\n",
            "Epoch 6/20\n",
            "705/705 [==============================] - 114s 162ms/step - loss: 0.0912 - val_loss: 0.0881\n",
            "Epoch 7/20\n",
            "705/705 [==============================] - 108s 153ms/step - loss: 0.0881 - val_loss: 0.0857\n",
            "Epoch 8/20\n",
            "705/705 [==============================] - 107s 151ms/step - loss: 0.0853 - val_loss: 0.0830\n",
            "Epoch 9/20\n",
            "705/705 [==============================] - 106s 151ms/step - loss: 0.0833 - val_loss: 0.0816\n",
            "Epoch 10/20\n",
            "705/705 [==============================] - 105s 149ms/step - loss: 0.0813 - val_loss: 0.0814\n",
            "Epoch 11/20\n",
            "705/705 [==============================] - 105s 149ms/step - loss: 0.0796 - val_loss: 0.0776\n",
            "Epoch 12/20\n",
            "705/705 [==============================] - 105s 149ms/step - loss: 0.0780 - val_loss: 0.0764\n",
            "Epoch 13/20\n",
            "705/705 [==============================] - 104s 147ms/step - loss: 0.0769 - val_loss: 0.0755\n",
            "Epoch 14/20\n",
            "705/705 [==============================] - 104s 148ms/step - loss: 0.0755 - val_loss: 0.0741\n",
            "Epoch 15/20\n",
            "705/705 [==============================] - 107s 152ms/step - loss: 0.0745 - val_loss: 0.0735\n",
            "Epoch 16/20\n",
            "705/705 [==============================] - 104s 147ms/step - loss: 0.0737 - val_loss: 0.0725\n",
            "Epoch 17/20\n",
            "705/705 [==============================] - 104s 148ms/step - loss: 0.0729 - val_loss: 0.0731\n",
            "Epoch 18/20\n",
            "705/705 [==============================] - 104s 147ms/step - loss: 0.0723 - val_loss: 0.0712\n",
            "Epoch 19/20\n",
            "705/705 [==============================] - 104s 147ms/step - loss: 0.0715 - val_loss: 0.0706\n",
            "Epoch 20/20\n",
            "705/705 [==============================] - 104s 147ms/step - loss: 0.0711 - val_loss: 0.0699\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Si2vs1lFLPQr",
        "outputId": "feff67e2-7957-4a4f-f6ed-b85f59cc824a"
      },
      "source": [
        "plt.figure(figsize=[6, 6])\n",
        "plt.plot(autoencoder_train.history['loss'])\n",
        "plt.plot(autoencoder_train.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper right')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aav5GR-eLPQr"
      },
      "source": [
        "preds = predict(autoencoder_train, test_data, threshold)\n",
        "print_stats(preds, test_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tROn4TajKYtv"
      },
      "source": [
        "##**Confusion Matrix**##"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zoPk8YW_LPQv",
        "outputId": "3ffa3210-4355-448c-8430-fc43c2c8b246"
      },
      "source": [
        "import numpy \n",
        "numpy.arange(3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZdEgL7W6KcQv",
        "outputId": "1ad8240e-c7d8-4226-cfad-669043db741f"
      },
      "source": [
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "n = 3\n",
        "ind = numpy.arange(n)\n",
        "width = 0.35\n",
        "x = ['Training dataset', 'Validation dataset', 'Testing dataset']\n",
        "svm = [0.86,0.76,0.76]\n",
        "cnn = [0.939,0.8615,0.8592]\n",
        "# plt.figure(figsize=[15, 10])\n",
        "plt.figure(figsize=[7, 6.5])\n",
        "plt.bar(ind,svm,width = 0.35)\n",
        "plt.bar(ind+width,cnn, width = 0.35)\n",
        "plt.legend(['svm','cnn'])\n",
        "plt.xticks([i+0.175 for i in range(3)], x)\n",
        "plt.ylabel('accuracy')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 504x468 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q74LDvERLPQw"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ppLGLaFNLPQw"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T1jxb1GvLPQw"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}